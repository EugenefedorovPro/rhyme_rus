{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from ipa_dicts import IpaDicts\n",
    "from ipapy import UNICODE_TO_IPA\n",
    "import ipapy\n",
    "from mysql_connect import MySql\n",
    "import dill\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# all_signs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "all_signs: list[ipapy.ipachar] = [s for s in IpaDicts().sign2number]\n",
    "print(len(all_signs))\n",
    "print(all_signs[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IpaSimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# all_signs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "all_signs: list[ipapy.ipachar] = [s for s in IpaDicts().sign2number]\n",
    "print(len(all_signs))\n",
    "print(all_signs[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IpaSimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class IpaSimilarities:\n",
    "    def __init__(self):\n",
    "        self.number: int = 0\n",
    "        self.root_phonetics: set[str] = set()\n",
    "        self.sign: ipapy.ipachar = None\n",
    "\n",
    "        self.similarities_sign: list[ipapy.ipachar] = []\n",
    "        self.similarities_uni: list[str] = []\n",
    "\n",
    "        self.similarities_frozen_name_sign: dict[frozenset, ipapy.ipachar] = {}\n",
    "        self.similarities_phone_features_score: dict[frozenset, int] = {}\n",
    "\n",
    "        self.similarities_sign_score: dict[ipapy.ipachar, int] = {}\n",
    "        self.similarities_uni_score: dict[str, int] = {}\n",
    "        self.similarities_int_score: dict[int, int] = {}\n",
    "        self.similarities_int_pattern: dict[int, str] = {}\n",
    "        self.uni_dict_uni_score: dict[str, dict[str, int]] = {}\n",
    "        self.similarities_phone_features_pattern: dict[frozenset, dict] = {}\n",
    "        self.similarities_sign_pattern: dict[ipapy.ipachar, str] = {}\n",
    "        self.int_dict_int_score: dict[int, dict[int, int]] = {}\n",
    "        self.int_dict_int_pattern: dict[int, dict[int, str]] = {}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.sign.name} from class IpaSimilarities\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "instances_ipasimilarities: list[IpaSimilarities] = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# consonants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set_signs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def set_signs(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _ipa in IpaDicts().all_ipa:\n",
    "        a = IpaSimilarities()\n",
    "        a.sign = _ipa\n",
    "        if a not in instances_ipasimilarities:\n",
    "            instances_ipasimilarities.append(a)\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = set_signs(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "voiced alveolar lateral-approximant velarized consonant prolonged from class IpaSimilarities\n"
     ]
    }
   ],
   "source": [
    "print(len(instances_ipasimilarities))\n",
    "print(instances_ipasimilarities[24])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_number(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign and not _instance.number:\n",
    "            _instance.number = IpaDicts().sign2number[_instance.sign]\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_number(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.number)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_all_root_phonetics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_all_root_phonetics(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if not instance.root_phonetics and instance.sign.is_consonant:\n",
    "            instance.root_phonetics = set(instance.sign.name.split())\n",
    "            instance.root_phonetics.discard(\"voiced\")\n",
    "            instance.root_phonetics.discard(\"voiceless\")\n",
    "            instance.root_phonetics.discard(\"prolonged\")\n",
    "            instance.root_phonetics.discard(\"palatalized\")\n",
    "            instance.root_phonetics.discard(\"consonant\")\n",
    "            instance.root_phonetics.discard(\"velarized\")\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "a\n",
      "set()\n",
      "b\n",
      "{'bilabial', 'plosive'}\n",
      "bʲ\n",
      "{'bilabial', 'plosive'}\n",
      "bʲː\n",
      "{'bilabial', 'plosive'}\n",
      "bː\n",
      "{'bilabial', 'plosive'}\n",
      "d\n",
      "{'alveolar', 'plosive'}\n",
      "dʲ\n",
      "{'alveolar', 'plosive'}\n",
      "dʲː\n",
      "{'alveolar', 'plosive'}\n",
      "dː\n",
      "{'alveolar', 'plosive'}\n",
      "d͡z\n",
      "{'alveolar', 'sibilant-affricate'}\n",
      "d͡zʲ\n",
      "{'alveolar', 'sibilant-affricate'}\n",
      "e\n",
      "set()\n",
      "f\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "fʲ\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "i\n",
      "set()\n",
      "j\n",
      "{'approximant', 'palatal'}\n",
      "jː\n",
      "{'palatal', 'approximant'}\n",
      "k\n",
      "{'velar', 'plosive'}\n",
      "kʲ\n",
      "{'velar', 'plosive'}\n",
      "kʲː\n",
      "{'velar', 'plosive'}\n",
      "kː\n",
      "{'velar', 'plosive'}\n",
      "lʲ\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "lʲː\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "lˠ\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "lˠː\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "m\n",
      "{'bilabial', 'nasal'}\n",
      "mʲ\n",
      "{'nasal', 'bilabial'}\n",
      "mʲː\n",
      "{'nasal', 'bilabial'}\n",
      "mː\n",
      "{'nasal', 'bilabial'}\n",
      "n\n",
      "{'alveolar', 'nasal'}\n",
      "nʲ\n",
      "{'alveolar', 'nasal'}\n",
      "nʲː\n",
      "{'alveolar', 'nasal'}\n",
      "nː\n",
      "{'alveolar', 'nasal'}\n",
      "o\n",
      "set()\n",
      "p\n",
      "{'bilabial', 'plosive'}\n",
      "pʲ\n",
      "{'bilabial', 'plosive'}\n",
      "pʲː\n",
      "{'bilabial', 'plosive'}\n",
      "pː\n",
      "{'bilabial', 'plosive'}\n",
      "r\n",
      "{'alveolar', 'trill'}\n",
      "rʲ\n",
      "{'alveolar', 'trill'}\n",
      "rʲː\n",
      "{'alveolar', 'trill'}\n",
      "rː\n",
      "{'alveolar', 'trill'}\n",
      "s\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "sʲ\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "sʲː\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "sː\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "t\n",
      "{'alveolar', 'plosive'}\n",
      "tʲ\n",
      "{'alveolar', 'plosive'}\n",
      "tʲː\n",
      "{'alveolar', 'plosive'}\n",
      "tː\n",
      "{'alveolar', 'plosive'}\n",
      "t͡s\n",
      "{'alveolar', 'sibilant-affricate'}\n",
      "t͡sʲ\n",
      "{'alveolar', 'sibilant-affricate'}\n",
      "t͡sː\n",
      "{'alveolar', 'sibilant-affricate'}\n",
      "t͡ɕ\n",
      "{'sibilant-affricate', 'alveolo-palatal'}\n",
      "t͡ɕː\n",
      "{'sibilant-affricate', 'alveolo-palatal'}\n",
      "u\n",
      "set()\n",
      "v\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "vʲ\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "vʲː\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "vː\n",
      "{'labio-dental', 'non-sibilant-fricative'}\n",
      "x\n",
      "{'velar', 'non-sibilant-fricative'}\n",
      "xʲ\n",
      "{'velar', 'non-sibilant-fricative'}\n",
      "z\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "zʲ\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "zʲː\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "zː\n",
      "{'alveolar', 'sibilant-fricative'}\n",
      "æ\n",
      "set()\n",
      "ɐ\n",
      "set()\n",
      "ɕ\n",
      "{'sibilant-fricative', 'alveolo-palatal'}\n",
      "ɕː\n",
      "{'sibilant-fricative', 'alveolo-palatal'}\n",
      "ə\n",
      "set()\n",
      "ɛ\n",
      "set()\n",
      "ɡ\n",
      "{'plosive', 'velar'}\n",
      "ɡʲ\n",
      "{'velar', 'plosive'}\n",
      "ɡː\n",
      "{'velar', 'plosive'}\n",
      "ɨ\n",
      "set()\n",
      "ɪ\n",
      "set()\n",
      "ɵ\n",
      "set()\n",
      "ʂ\n",
      "{'retroflex', 'sibilant-fricative'}\n",
      "ʂː\n",
      "{'retroflex', 'sibilant-fricative'}\n",
      "ʈ͡ʂ\n",
      "{'retroflex', 'sibilant-affricate'}\n",
      "ʉ\n",
      "set()\n",
      "ʊ\n",
      "set()\n",
      "ʐ\n",
      "{'retroflex', 'sibilant-fricative'}\n",
      "ʐː\n",
      "{'retroflex', 'sibilant-fricative'}\n"
     ]
    }
   ],
   "source": [
    "instances_ipasimilarities = get_all_root_phonetics(instances_ipasimilarities)\n",
    "print(len(instances_ipasimilarities))\n",
    "for item in instances_ipasimilarities:\n",
    "    print(item.sign)\n",
    "    print(item.root_phonetics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_similarities_sign"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_similarities_sign(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for instance_target in instances_ipasimilarities:\n",
    "        if instance_target.sign.is_consonant:\n",
    "            target_root_phonetics = instance_target.root_phonetics\n",
    "            for instance_find in instances_ipasimilarities:\n",
    "                if target_root_phonetics == instance_find.root_phonetics:\n",
    "                    if instance_find.sign not in instance_target.similarities_sign:\n",
    "                        instance_target.similarities_sign.append(instance_find.sign)\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ b\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ bʲ\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ bʲː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ bː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ d\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ dʲ\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ dʲː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ dː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ d͡z\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "_______ d͡zʲ\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "_______ f\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ fʲ\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ j\n",
      "j\n",
      "jː\n",
      "_______ jː\n",
      "j\n",
      "jː\n",
      "_______ k\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ kʲ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ kʲː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ kː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ lʲ\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "_______ lʲː\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "_______ lˠ\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "_______ lˠː\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "_______ m\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "_______ mʲ\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "_______ mʲː\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "_______ mː\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "_______ n\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "_______ nʲ\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "_______ nʲː\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "_______ nː\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "_______ p\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ pʲ\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ pʲː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ pː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "_______ r\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "_______ rʲ\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "_______ rʲː\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "_______ rː\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "_______ s\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ sʲ\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ sʲː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ sː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ t\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ tʲ\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ tʲː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ tː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "_______ t͡s\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "_______ t͡sʲ\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "_______ t͡sː\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "_______ t͡ɕ\n",
      "t͡ɕ\n",
      "t͡ɕː\n",
      "_______ t͡ɕː\n",
      "t͡ɕ\n",
      "t͡ɕː\n",
      "_______ v\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ vʲ\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ vʲː\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ vː\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "_______ x\n",
      "x\n",
      "xʲ\n",
      "_______ xʲ\n",
      "x\n",
      "xʲ\n",
      "_______ z\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ zʲ\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ zʲː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ zː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "_______ ɕ\n",
      "ɕ\n",
      "ɕː\n",
      "_______ ɕː\n",
      "ɕ\n",
      "ɕː\n",
      "_______ ɡ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ ɡʲ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ ɡː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "_______ ʂ\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "_______ ʂː\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "_______ ʈ͡ʂ\n",
      "ʈ͡ʂ\n",
      "_______ ʐ\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "_______ ʐː\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n"
     ]
    }
   ],
   "source": [
    "instances_ipasimilarities = get_similarities_sign(instances_ipasimilarities)\n",
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_consonant:\n",
    "        print(\"_______\", instance.sign)\n",
    "        for _sign in instance.similarities_sign:\n",
    "            print(_sign)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_similarities_uni"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_similarities_uni(instances_ipasimilarities: list[IpaSimilarities]):\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if instance.similarities_sign:\n",
    "            instance.similarities_uni = [str(_ipa) for _ipa in instance.similarities_sign]\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________ a\n",
      "____________ b\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ bʲ\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ bʲː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ bː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ d\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ dʲ\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ dʲː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ dː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ d͡z\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "____________ d͡zʲ\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "____________ e\n",
      "____________ f\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ fʲ\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ i\n",
      "____________ j\n",
      "j\n",
      "jː\n",
      "____________ jː\n",
      "j\n",
      "jː\n",
      "____________ k\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ kʲ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ kʲː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ kː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ lʲ\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "____________ lʲː\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "____________ lˠ\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "____________ lˠː\n",
      "lʲ\n",
      "lʲː\n",
      "lˠ\n",
      "lˠː\n",
      "____________ m\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "____________ mʲ\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "____________ mʲː\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "____________ mː\n",
      "m\n",
      "mʲ\n",
      "mʲː\n",
      "mː\n",
      "____________ n\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "____________ nʲ\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "____________ nʲː\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "____________ nː\n",
      "n\n",
      "nʲ\n",
      "nʲː\n",
      "nː\n",
      "____________ o\n",
      "____________ p\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ pʲ\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ pʲː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ pː\n",
      "b\n",
      "bʲ\n",
      "bʲː\n",
      "bː\n",
      "p\n",
      "pʲ\n",
      "pʲː\n",
      "pː\n",
      "____________ r\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "____________ rʲ\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "____________ rʲː\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "____________ rː\n",
      "r\n",
      "rʲ\n",
      "rʲː\n",
      "rː\n",
      "____________ s\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ sʲ\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ sʲː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ sː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ t\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ tʲ\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ tʲː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ tː\n",
      "d\n",
      "dʲ\n",
      "dʲː\n",
      "dː\n",
      "t\n",
      "tʲ\n",
      "tʲː\n",
      "tː\n",
      "____________ t͡s\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "____________ t͡sʲ\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "____________ t͡sː\n",
      "d͡z\n",
      "d͡zʲ\n",
      "t͡s\n",
      "t͡sʲ\n",
      "t͡sː\n",
      "____________ t͡ɕ\n",
      "t͡ɕ\n",
      "t͡ɕː\n",
      "____________ t͡ɕː\n",
      "t͡ɕ\n",
      "t͡ɕː\n",
      "____________ u\n",
      "____________ v\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ vʲ\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ vʲː\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ vː\n",
      "f\n",
      "fʲ\n",
      "v\n",
      "vʲ\n",
      "vʲː\n",
      "vː\n",
      "____________ x\n",
      "x\n",
      "xʲ\n",
      "____________ xʲ\n",
      "x\n",
      "xʲ\n",
      "____________ z\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ zʲ\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ zʲː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ zː\n",
      "s\n",
      "sʲ\n",
      "sʲː\n",
      "sː\n",
      "z\n",
      "zʲ\n",
      "zʲː\n",
      "zː\n",
      "____________ æ\n",
      "____________ ɐ\n",
      "____________ ɕ\n",
      "ɕ\n",
      "ɕː\n",
      "____________ ɕː\n",
      "ɕ\n",
      "ɕː\n",
      "____________ ə\n",
      "____________ ɛ\n",
      "____________ ɡ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ ɡʲ\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ ɡː\n",
      "k\n",
      "kʲ\n",
      "kʲː\n",
      "kː\n",
      "ɡ\n",
      "ɡʲ\n",
      "ɡː\n",
      "____________ ɨ\n",
      "____________ ɪ\n",
      "____________ ɵ\n",
      "____________ ʂ\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "____________ ʂː\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "____________ ʈ͡ʂ\n",
      "ʈ͡ʂ\n",
      "____________ ʉ\n",
      "____________ ʊ\n",
      "____________ ʐ\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n",
      "____________ ʐː\n",
      "ʂ\n",
      "ʂː\n",
      "ʐ\n",
      "ʐː\n"
     ]
    }
   ],
   "source": [
    "instances_ipasimilarities = get_similarities_uni(instances_ipasimilarities)\n",
    "for instance in instances_ipasimilarities:\n",
    "    print(\"____________\", instance.sign)\n",
    "    for _uni in instance.similarities_uni:\n",
    "        print(_uni)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_similarities_frozen_name_sign"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_similarities_frozen_name_sign(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        for _ipa in _instance.similarities_sign:\n",
    "            frozen_name = frozenset(_ipa.name.split())\n",
    "            _instance.similarities_frozen_name_sign[frozen_name] = _ipa\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "{frozenset({'bilabial',\n            'consonant',\n            'plosive',\n            'voiced'}): bilabial consonant plosive voiced,\n frozenset({'bilabial',\n            'consonant',\n            'palatalized',\n            'plosive',\n            'voiced'}): bilabial consonant palatalized plosive voiced,\n frozenset({'bilabial',\n            'consonant',\n            'palatalized',\n            'plosive',\n            'prolonged',\n            'voiced'}): bilabial consonant palatalized plosive voiced,\n frozenset({'bilabial',\n            'consonant',\n            'plosive',\n            'prolonged',\n            'voiced'}): bilabial consonant plosive voiced,\n frozenset({'bilabial',\n            'consonant',\n            'plosive',\n            'voiceless'}): bilabial consonant plosive voiceless,\n frozenset({'bilabial',\n            'consonant',\n            'palatalized',\n            'plosive',\n            'voiceless'}): bilabial consonant palatalized plosive voiceless,\n frozenset({'bilabial',\n            'consonant',\n            'palatalized',\n            'plosive',\n            'prolonged',\n            'voiceless'}): bilabial consonant palatalized plosive voiceless,\n frozenset({'bilabial',\n            'consonant',\n            'plosive',\n            'prolonged',\n            'voiceless'}): bilabial consonant plosive voiceless}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_ipasimilarities = get_similarities_frozen_name_sign(instances_ipasimilarities)\n",
    "instances_ipasimilarities[3].similarities_frozen_name_sign"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'alveolar', 'palatalized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲ\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲː\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠ\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠː\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲ\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲː\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠ\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠː\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲ\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲː\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠ\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠː\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲ\n",
      "___________________\n",
      "frozenset({'alveolar', 'palatalized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lʲː\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠ\n",
      "___________________\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "lˠː\n",
      "___________________\n",
      "frozenset({'bilabial', 'consonant', 'voiced', 'nasal'})\n",
      "m\n",
      "___________________\n",
      "frozenset({'nasal', 'palatalized', 'bilabial', 'voiced', 'consonant'})\n",
      "mʲ\n",
      "___________________\n",
      "frozenset({'nasal', 'palatalized', 'bilabial', 'prolonged', 'voiced', 'consonant'})\n",
      "mʲː\n",
      "___________________\n",
      "frozenset({'nasal', 'bilabial', 'prolonged', 'voiced', 'consonant'})\n",
      "mː\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(22, 27):\n",
    "        for key in instance.similarities_frozen_name_sign:\n",
    "            print(key)\n",
    "            print(instance.similarities_frozen_name_sign[key])\n",
    "            print(\"___________________\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def set_scores() -> list[int]:\n",
    "    same_score = 0\n",
    "    voice_score = 1\n",
    "    palatalized_score = 2\n",
    "    prolonged_sore = 1\n",
    "    voice_prolonged_score = 1\n",
    "    scores: list[int] = [same_score, voice_score, palatalized_score, prolonged_sore, voice_prolonged_score]\n",
    "    return scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "scores = set_scores()\n",
    "print(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alveolar', 'lateral-approximant'}\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "{'alveolar', 'lateral-approximant'}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(22, 25):\n",
    "        print(instance.root_phonetics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AssignPhoneFeaturesScore:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class AssignPhoneFeaturesScore:\n",
    "    def __init__(self, instances_ipasimilarities):\n",
    "        self.instances_ipasimilarities = instances_ipasimilarities\n",
    "\n",
    "    @classmethod\n",
    "    def __get_palatalized(cls, base_name: set[str]):\n",
    "        if \"lateral-approximant\" in base_name and \"alveolar\" in base_name:\n",
    "            base_name_copy = cls.__get_palatalized_for_l(base_name)\n",
    "        else:\n",
    "            base_name_copy = cls.__get_palatalized_for_any_but_l(base_name)\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_palatalized_for_any_but_l(cls, base_name: set[str]):\n",
    "        base_name_copy = base_name.copy()\n",
    "        if \"palatalized\" in base_name_copy:\n",
    "            base_name_copy.discard(\"palatalized\")\n",
    "        else:\n",
    "            base_name_copy.update((\"palatalized\",))\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_palatalized_for_l(cls, base_name: set[str]):\n",
    "        base_name_copy = base_name.copy()\n",
    "        if \"palatalized\" in base_name_copy:\n",
    "            base_name_copy.discard(\"palatalized\")\n",
    "            base_name_copy.update((\"velarized\",))\n",
    "        else:\n",
    "            base_name_copy.discard(\"velarized\")\n",
    "            base_name_copy.update((\"palatalized\",))\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_voice(cls, base_name: set[str]):\n",
    "        base_name_copy = base_name.copy()\n",
    "        if \"voiced\" in base_name_copy:\n",
    "            base_name_copy.discard(\"voiced\")\n",
    "            base_name_copy.update((\"voiceless\",))\n",
    "        else:\n",
    "            base_name_copy.discard(\"voiceless\")\n",
    "            base_name_copy.update((\"voiced\",))\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_prolonged(cls, base_name: set[str]):\n",
    "        base_name_copy = base_name.copy()\n",
    "        if \"prolonged\" in base_name_copy:\n",
    "            base_name_copy.discard(\"prolonged\")\n",
    "        else:\n",
    "            base_name_copy.update((\"prolonged\",))\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_voice_prolonged(cls, base_name: set[str]):\n",
    "        base_name_copy = base_name.copy()\n",
    "        base_name_copy = cls.__get_voice(base_name_copy)\n",
    "        base_name_copy = cls.__get_prolonged(base_name_copy)\n",
    "        return base_name_copy\n",
    "\n",
    "    @classmethod\n",
    "    def __get_inversions(cls, base_name: set[str]) -> list[set[str]]:\n",
    "        same = base_name.copy()\n",
    "        voice = cls.__get_voice(base_name)\n",
    "        palatalized = cls.__get_palatalized(base_name)\n",
    "        prolonged = cls.__get_prolonged(base_name)\n",
    "        voice_prolonged = cls.__get_voice_prolonged(base_name)\n",
    "        inversions: list[set[str]] = [same, voice, palatalized, prolonged, voice_prolonged]\n",
    "        return inversions\n",
    "\n",
    "    @classmethod\n",
    "    def __get_patterns(cls) -> list[str]:\n",
    "        same_score = \"same_cons\"\n",
    "        voice_score = \"voice\"\n",
    "        palatalized_score = \"palat\"\n",
    "        prolonged_sore = \"prolong\"\n",
    "        voice_prolonged_score = \"voice_prolong\"\n",
    "        patterns: list[str] = [same_score, voice_score, palatalized_score, prolonged_sore, voice_prolonged_score]\n",
    "        return patterns\n",
    "\n",
    "    @classmethod\n",
    "    def __get_similarities(cls, instance: IpaSimilarities) -> IpaSimilarities:\n",
    "        similarities: list = []\n",
    "        if instance.sign.is_consonant:\n",
    "            for item in instance.similarities_sign:\n",
    "                similarities.append(set(item.name.split()))\n",
    "        return similarities\n",
    "\n",
    "    @classmethod\n",
    "    def __get_base_name(cls, instance: IpaSimilarities) -> IpaSimilarities:\n",
    "        base_name: set[str] = set(instance.sign.name.split())\n",
    "        return base_name\n",
    "\n",
    "    @classmethod\n",
    "    def __assign_phone_features_score(cls, instance: IpaSimilarities) -> IpaSimilarities:\n",
    "        base_name: set[str] = cls.__get_base_name(instance)\n",
    "        similarities = cls.__get_similarities(instance)\n",
    "        scores = set_scores()\n",
    "        inversions = cls.__get_inversions(base_name)\n",
    "\n",
    "        for inv, scr in zip(inversions, scores):\n",
    "            if inv in similarities:\n",
    "                instance.similarities_phone_features_score[frozenset(inv)] = scr\n",
    "\n",
    "        return instance\n",
    "\n",
    "    @classmethod\n",
    "    def __assign_phone_features_pattern(cls, instance: IpaSimilarities) -> IpaSimilarities:\n",
    "        base_name: set[str] = cls.__get_base_name(instance)\n",
    "        similarities = cls.__get_similarities(instance)\n",
    "\n",
    "        patterns = cls.__get_patterns()\n",
    "        inversions = cls.__get_inversions(base_name)\n",
    "\n",
    "        for inv, pat in zip(inversions, patterns):\n",
    "            if inv in similarities:\n",
    "                instance.similarities_phone_features_pattern[frozenset(inv)] = pat\n",
    "\n",
    "        return instance\n",
    "\n",
    "    def assign_phone_features_score(self):\n",
    "        for _instance in self.instances_ipasimilarities:\n",
    "            _instance = AssignPhoneFeaturesScore.__assign_phone_features_score(_instance)\n",
    "        return instances_ipasimilarities\n",
    "\n",
    "    def assign_phone_features_pattern(self):\n",
    "        for _instance in self.instances_ipasimilarities:\n",
    "            _instance = AssignPhoneFeaturesScore.__assign_phone_features_pattern(_instance)\n",
    "        return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lʲ\n",
      "voiced alveolar lateral-approximant consonant palatalized\n",
      "lʲː\n",
      "voiced alveolar lateral-approximant consonant palatalized prolonged\n",
      "lˠ\n",
      "voiced alveolar lateral-approximant velarized consonant\n",
      "lˠː\n",
      "voiced alveolar lateral-approximant velarized consonant prolonged\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(22, 26):\n",
    "        print(instance.sign)\n",
    "        print(instance.sign.name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_phone_features_pattern\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_phone_features_pattern(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    instances_ipasimilarities = AssignPhoneFeaturesScore(instances_ipasimilarities).assign_phone_features_pattern()\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_phone_features_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kː 21 voiceless velar plosive consonant prolonged\n",
      "{frozenset({'voiceless', 'velar', 'plosive', 'prolonged', 'consonant'}): 'same_cons', frozenset({'velar', 'prolonged', 'plosive', 'voiced', 'consonant'}): 'voice', frozenset({'voiceless', 'velar', 'plosive', 'palatalized', 'prolonged', 'consonant'}): 'palat', frozenset({'voiceless', 'velar', 'plosive', 'consonant'}): 'prolong', frozenset({'consonant', 'velar', 'plosive', 'voiced'}): 'voice_prolong'}\n",
      "_______________________\n",
      "lʲ 22 voiced alveolar lateral-approximant consonant palatalized\n",
      "{frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'}): 'same_cons', frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'}): 'palat', frozenset({'alveolar', 'prolonged', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'}): 'prolong'}\n",
      "_______________________\n",
      "lʲː 23 voiced alveolar lateral-approximant consonant palatalized prolonged\n",
      "{frozenset({'alveolar', 'lateral-approximant', 'voiced', 'palatalized', 'prolonged', 'consonant'}): 'same_cons', frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'}): 'palat', frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'}): 'prolong'}\n",
      "_______________________\n",
      "lˠ 24 voiced alveolar lateral-approximant velarized consonant\n",
      "{frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'}): 'same_cons', frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'}): 'palat', frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'}): 'prolong'}\n",
      "_______________________\n",
      "lˠː 25 voiced alveolar lateral-approximant velarized consonant prolonged\n",
      "{frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'prolonged', 'consonant'}): 'same_cons', frozenset({'alveolar', 'prolonged', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'}): 'palat', frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'}): 'prolong'}\n",
      "_______________________\n",
      "m 26 voiced bilabial nasal consonant\n",
      "{frozenset({'bilabial', 'consonant', 'voiced', 'nasal'}): 'same_cons', frozenset({'nasal', 'palatalized', 'bilabial', 'voiced', 'consonant'}): 'palat', frozenset({'nasal', 'voiced', 'bilabial', 'prolonged', 'consonant'}): 'prolong'}\n",
      "_______________________\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(21, 27):\n",
    "        print(instance.sign, instance.number, instance.sign.name)\n",
    "        print(instance.similarities_phone_features_pattern)\n",
    "        print(\"_______________________\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_phone_features_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def get_phone_features_score(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    instances_ipasimilarities = AssignPhoneFeaturesScore(instances_ipasimilarities).assign_phone_features_score()\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_phone_features_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lʲ 22\n",
      "frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'})\n",
      "0\n",
      "lʲ 22\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "2\n",
      "lʲ 22\n",
      "frozenset({'alveolar', 'prolonged', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'})\n",
      "1\n",
      "lʲː 23\n",
      "frozenset({'alveolar', 'lateral-approximant', 'voiced', 'palatalized', 'prolonged', 'consonant'})\n",
      "0\n",
      "lʲː 23\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "2\n",
      "lʲː 23\n",
      "frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'})\n",
      "1\n",
      "lˠ 24\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "0\n",
      "lˠ 24\n",
      "frozenset({'alveolar', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'})\n",
      "2\n",
      "lˠ 24\n",
      "frozenset({'alveolar', 'velarized', 'prolonged', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "1\n",
      "lˠː 25\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'prolonged', 'consonant'})\n",
      "0\n",
      "lˠː 25\n",
      "frozenset({'alveolar', 'prolonged', 'lateral-approximant', 'palatalized', 'voiced', 'consonant'})\n",
      "2\n",
      "lˠː 25\n",
      "frozenset({'alveolar', 'velarized', 'lateral-approximant', 'voiced', 'consonant'})\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(22, 26):\n",
    "        for key in instance.similarities_phone_features_score:\n",
    "            print(instance.sign, instance.number)\n",
    "            print(key)\n",
    "            print(instance.similarities_phone_features_score[key])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_sign_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_sign_score(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_consonant:\n",
    "            for _frozen_name in _instance.similarities_frozen_name_sign:\n",
    "                _sign = _instance.similarities_frozen_name_sign[_frozen_name]\n",
    "                try:\n",
    "                    _score = _instance.similarities_phone_features_score[_frozen_name]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                _instance.similarities_sign_score[_sign] = _score\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_sign_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kː 21 voiceless velar plosive consonant prolonged\n",
      "{consonant plosive velar voiceless: 1, consonant palatalized plosive velar voiceless: 1, consonant palatalized plosive velar voiceless: 2, consonant plosive velar voiceless: 0, consonant plosive velar voiced: 1, consonant palatalized plosive velar voiced: 1, consonant plosive velar voiced: 1}\n",
      "_______________________\n",
      "lʲ 22 voiced alveolar lateral-approximant consonant palatalized\n",
      "{alveolar consonant lateral-approximant palatalized voiced: 0, alveolar consonant lateral-approximant palatalized voiced: 1, alveolar consonant lateral-approximant velarized voiced: 2, alveolar consonant lateral-approximant velarized voiced: 2}\n",
      "_______________________\n",
      "lʲː 23 voiced alveolar lateral-approximant consonant palatalized prolonged\n",
      "{alveolar consonant lateral-approximant palatalized voiced: 1, alveolar consonant lateral-approximant palatalized voiced: 0, alveolar consonant lateral-approximant velarized voiced: 0, alveolar consonant lateral-approximant velarized voiced: 2}\n",
      "_______________________\n",
      "lˠ 24 voiced alveolar lateral-approximant velarized consonant\n",
      "{alveolar consonant lateral-approximant palatalized voiced: 2, alveolar consonant lateral-approximant palatalized voiced: 2, alveolar consonant lateral-approximant velarized voiced: 0, alveolar consonant lateral-approximant velarized voiced: 1}\n",
      "_______________________\n",
      "lˠː 25 voiced alveolar lateral-approximant velarized consonant prolonged\n",
      "{alveolar consonant lateral-approximant palatalized voiced: 1, alveolar consonant lateral-approximant palatalized voiced: 2, alveolar consonant lateral-approximant velarized voiced: 1, alveolar consonant lateral-approximant velarized voiced: 0}\n",
      "_______________________\n",
      "m 26 voiced bilabial nasal consonant\n",
      "{bilabial consonant nasal voiced: 0, bilabial consonant nasal palatalized voiced: 2, bilabial consonant nasal palatalized voiced: 2, bilabial consonant nasal voiced: 1}\n",
      "_______________________\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in range(21, 27):\n",
    "        print(instance.sign, instance.number, instance.sign.name)\n",
    "        print(instance.similarities_sign_score)\n",
    "        print(\"_______________________\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_uni_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def get_uni_score(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_consonant:\n",
    "            for _frozen_name in _instance.similarities_frozen_name_sign:\n",
    "                _sign = _instance.similarities_frozen_name_sign[_frozen_name]\n",
    "                try:\n",
    "                    _score = _instance.similarities_phone_features_score[_frozen_name]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                _instance.similarities_uni_score[str(_sign)] = _score\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_uni_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "{}\n",
      "_______________\n",
      "b\n",
      "{'b': 0, 'bʲ': 2, 'bʲː': 2, 'bː': 1, 'p': 1, 'pʲ': 1, 'pʲː': 1, 'pː': 1}\n",
      "_______________\n",
      "bʲ\n",
      "{'b': 2, 'bʲ': 0, 'bʲː': 1, 'bː': 1, 'p': 1, 'pʲ': 1, 'pʲː': 1, 'pː': 1}\n",
      "_______________\n",
      "bʲː\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 0, 'bː': 2, 'p': 2, 'pʲ': 1, 'pʲː': 1, 'pː': 1}\n",
      "_______________\n",
      "bː\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 2, 'bː': 0, 'p': 1, 'pʲ': 1, 'pʲː': 1, 'pː': 1}\n",
      "_______________\n",
      "d\n",
      "{'d': 0, 'dʲ': 2, 'dʲː': 2, 'dː': 1, 't': 1, 'tʲ': 1, 'tʲː': 1, 'tː': 1}\n",
      "_______________\n",
      "dʲ\n",
      "{'d': 2, 'dʲ': 0, 'dʲː': 1, 'dː': 1, 't': 1, 'tʲ': 1, 'tʲː': 1, 'tː': 1}\n",
      "_______________\n",
      "dʲː\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 0, 'dː': 2, 't': 2, 'tʲ': 1, 'tʲː': 1, 'tː': 1}\n",
      "_______________\n",
      "dː\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 2, 'dː': 0, 't': 1, 'tʲ': 1, 'tʲː': 1, 'tː': 1}\n",
      "_______________\n",
      "d͡z\n",
      "{'d͡z': 0, 'd͡zʲ': 2, 't͡s': 1, 't͡sʲ': 1, 't͡sː': 1}\n",
      "_______________\n",
      "d͡zʲ\n",
      "{'d͡z': 2, 'd͡zʲ': 0, 't͡s': 0, 't͡sʲ': 1, 't͡sː': 1}\n",
      "_______________\n",
      "e\n",
      "{}\n",
      "_______________\n",
      "f\n",
      "{'f': 0, 'fʲ': 2, 'v': 1, 'vʲ': 1, 'vʲː': 1, 'vː': 1}\n",
      "_______________\n",
      "fʲ\n",
      "{'f': 2, 'fʲ': 0, 'v': 0, 'vʲ': 1, 'vʲː': 1, 'vː': 1}\n",
      "_______________\n",
      "i\n",
      "{}\n",
      "_______________\n",
      "j\n",
      "{'j': 0, 'jː': 1}\n",
      "_______________\n",
      "jː\n",
      "{'j': 1, 'jː': 0}\n",
      "_______________\n",
      "k\n",
      "{'k': 0, 'kʲ': 2, 'kʲː': 2, 'kː': 1, 'ɡ': 1, 'ɡʲ': 1, 'ɡː': 1}\n",
      "_______________\n",
      "kʲ\n",
      "{'k': 2, 'kʲ': 0, 'kʲː': 1, 'kː': 1, 'ɡ': 1, 'ɡʲ': 1, 'ɡː': 1}\n",
      "_______________\n",
      "kʲː\n",
      "{'k': 1, 'kʲ': 1, 'kʲː': 0, 'kː': 2, 'ɡ': 2, 'ɡʲ': 1, 'ɡː': 1}\n",
      "_______________\n",
      "kː\n",
      "{'k': 1, 'kʲ': 1, 'kʲː': 2, 'kː': 0, 'ɡ': 1, 'ɡʲ': 1, 'ɡː': 1}\n",
      "_______________\n",
      "lʲ\n",
      "{'lʲ': 0, 'lʲː': 1, 'lˠ': 2, 'lˠː': 2}\n",
      "_______________\n",
      "lʲː\n",
      "{'lʲ': 1, 'lʲː': 0, 'lˠ': 0, 'lˠː': 2}\n",
      "_______________\n",
      "lˠ\n",
      "{'lʲ': 2, 'lʲː': 2, 'lˠ': 0, 'lˠː': 1}\n",
      "_______________\n",
      "lˠː\n",
      "{'lʲ': 1, 'lʲː': 2, 'lˠ': 1, 'lˠː': 0}\n",
      "_______________\n",
      "m\n",
      "{'m': 0, 'mʲ': 2, 'mʲː': 2, 'mː': 1}\n",
      "_______________\n",
      "mʲ\n",
      "{'m': 2, 'mʲ': 0, 'mʲː': 1, 'mː': 1}\n",
      "_______________\n",
      "mʲː\n",
      "{'m': 1, 'mʲ': 1, 'mʲː': 0, 'mː': 2}\n",
      "_______________\n",
      "mː\n",
      "{'m': 1, 'mʲ': 1, 'mʲː': 2, 'mː': 0}\n",
      "_______________\n",
      "n\n",
      "{'n': 0, 'nʲ': 2, 'nʲː': 2, 'nː': 1}\n",
      "_______________\n",
      "nʲ\n",
      "{'n': 2, 'nʲ': 0, 'nʲː': 1, 'nː': 1}\n",
      "_______________\n",
      "nʲː\n",
      "{'n': 1, 'nʲ': 1, 'nʲː': 0, 'nː': 2}\n",
      "_______________\n",
      "nː\n",
      "{'n': 1, 'nʲ': 1, 'nʲː': 2, 'nː': 0}\n",
      "_______________\n",
      "o\n",
      "{}\n",
      "_______________\n",
      "p\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 1, 'bː': 1, 'p': 0, 'pʲ': 2, 'pʲː': 2, 'pː': 1}\n",
      "_______________\n",
      "pʲ\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 1, 'bː': 1, 'p': 2, 'pʲ': 0, 'pʲː': 1, 'pː': 1}\n",
      "_______________\n",
      "pʲː\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 1, 'bː': 1, 'p': 1, 'pʲ': 1, 'pʲː': 0, 'pː': 2}\n",
      "_______________\n",
      "pː\n",
      "{'b': 1, 'bʲ': 1, 'bʲː': 1, 'bː': 1, 'p': 1, 'pʲ': 1, 'pʲː': 2, 'pː': 0}\n",
      "_______________\n",
      "r\n",
      "{'r': 0, 'rʲ': 2, 'rʲː': 2, 'rː': 1}\n",
      "_______________\n",
      "rʲ\n",
      "{'r': 2, 'rʲ': 0, 'rʲː': 1, 'rː': 1}\n",
      "_______________\n",
      "rʲː\n",
      "{'r': 1, 'rʲ': 1, 'rʲː': 0, 'rː': 2}\n",
      "_______________\n",
      "rː\n",
      "{'r': 1, 'rʲ': 1, 'rʲː': 2, 'rː': 0}\n",
      "_______________\n",
      "s\n",
      "{'s': 0, 'sʲ': 2, 'sʲː': 2, 'sː': 1, 'z': 1, 'zʲ': 1, 'zʲː': 1, 'zː': 1}\n",
      "_______________\n",
      "sʲ\n",
      "{'s': 2, 'sʲ': 0, 'sʲː': 1, 'sː': 1, 'z': 1, 'zʲ': 1, 'zʲː': 1, 'zː': 1}\n",
      "_______________\n",
      "sʲː\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 0, 'sː': 2, 'z': 2, 'zʲ': 1, 'zʲː': 1, 'zː': 1}\n",
      "_______________\n",
      "sː\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 2, 'sː': 0, 'z': 1, 'zʲ': 1, 'zʲː': 1, 'zː': 1}\n",
      "_______________\n",
      "t\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 1, 'dː': 1, 't': 0, 'tʲ': 2, 'tʲː': 2, 'tː': 1}\n",
      "_______________\n",
      "tʲ\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 1, 'dː': 1, 't': 2, 'tʲ': 0, 'tʲː': 1, 'tː': 1}\n",
      "_______________\n",
      "tʲː\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 1, 'dː': 1, 't': 1, 'tʲ': 1, 'tʲː': 0, 'tː': 2}\n",
      "_______________\n",
      "tː\n",
      "{'d': 1, 'dʲ': 1, 'dʲː': 1, 'dː': 1, 't': 1, 'tʲ': 1, 'tʲː': 2, 'tː': 0}\n",
      "_______________\n",
      "t͡s\n",
      "{'d͡z': 1, 'd͡zʲ': 1, 't͡s': 0, 't͡sʲ': 2, 't͡sː': 1}\n",
      "_______________\n",
      "t͡sʲ\n",
      "{'d͡z': 1, 'd͡zʲ': 1, 't͡s': 2, 't͡sʲ': 0, 't͡sː': 0}\n",
      "_______________\n",
      "t͡sː\n",
      "{'d͡z': 1, 'd͡zʲ': 1, 't͡s': 1, 't͡sʲ': 1, 't͡sː': 0}\n",
      "_______________\n",
      "t͡ɕ\n",
      "{'t͡ɕ': 0, 't͡ɕː': 1}\n",
      "_______________\n",
      "t͡ɕː\n",
      "{'t͡ɕ': 1, 't͡ɕː': 0}\n",
      "_______________\n",
      "u\n",
      "{}\n",
      "_______________\n",
      "v\n",
      "{'f': 1, 'fʲ': 1, 'v': 0, 'vʲ': 2, 'vʲː': 2, 'vː': 1}\n",
      "_______________\n",
      "vʲ\n",
      "{'f': 1, 'fʲ': 1, 'v': 2, 'vʲ': 0, 'vʲː': 1, 'vː': 1}\n",
      "_______________\n",
      "vʲː\n",
      "{'f': 1, 'fʲ': 1, 'v': 1, 'vʲ': 1, 'vʲː': 0, 'vː': 2}\n",
      "_______________\n",
      "vː\n",
      "{'f': 1, 'fʲ': 1, 'v': 1, 'vʲ': 1, 'vʲː': 2, 'vː': 0}\n",
      "_______________\n",
      "x\n",
      "{'x': 0, 'xʲ': 2}\n",
      "_______________\n",
      "xʲ\n",
      "{'x': 2, 'xʲ': 0}\n",
      "_______________\n",
      "z\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 1, 'sː': 1, 'z': 0, 'zʲ': 2, 'zʲː': 2, 'zː': 1}\n",
      "_______________\n",
      "zʲ\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 1, 'sː': 1, 'z': 2, 'zʲ': 0, 'zʲː': 1, 'zː': 1}\n",
      "_______________\n",
      "zʲː\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 1, 'sː': 1, 'z': 1, 'zʲ': 1, 'zʲː': 0, 'zː': 2}\n",
      "_______________\n",
      "zː\n",
      "{'s': 1, 'sʲ': 1, 'sʲː': 1, 'sː': 1, 'z': 1, 'zʲ': 1, 'zʲː': 2, 'zː': 0}\n",
      "_______________\n",
      "æ\n",
      "{}\n",
      "_______________\n",
      "ɐ\n",
      "{}\n",
      "_______________\n",
      "ɕ\n",
      "{'ɕ': 0, 'ɕː': 1}\n",
      "_______________\n",
      "ɕː\n",
      "{'ɕ': 1, 'ɕː': 0}\n",
      "_______________\n",
      "ə\n",
      "{}\n",
      "_______________\n",
      "ɛ\n",
      "{}\n",
      "_______________\n",
      "ɡ\n",
      "{'k': 1, 'kʲ': 1, 'kʲː': 1, 'kː': 1, 'ɡ': 0, 'ɡʲ': 2, 'ɡː': 1}\n",
      "_______________\n",
      "ɡʲ\n",
      "{'k': 1, 'kʲ': 1, 'kʲː': 1, 'kː': 1, 'ɡ': 2, 'ɡʲ': 0, 'ɡː': 0}\n",
      "_______________\n",
      "ɡː\n",
      "{'k': 1, 'kʲ': 1, 'kʲː': 1, 'kː': 1, 'ɡ': 1, 'ɡʲ': 1, 'ɡː': 0}\n",
      "_______________\n",
      "ɨ\n",
      "{}\n",
      "_______________\n",
      "ɪ\n",
      "{}\n",
      "_______________\n",
      "ɵ\n",
      "{}\n",
      "_______________\n",
      "ʂ\n",
      "{'ʂ': 0, 'ʂː': 1, 'ʐ': 1, 'ʐː': 1}\n",
      "_______________\n",
      "ʂː\n",
      "{'ʂ': 1, 'ʂː': 0, 'ʐ': 1, 'ʐː': 1}\n",
      "_______________\n",
      "ʈ͡ʂ\n",
      "{'ʈ͡ʂ': 0}\n",
      "_______________\n",
      "ʉ\n",
      "{}\n",
      "_______________\n",
      "ʊ\n",
      "{}\n",
      "_______________\n",
      "ʐ\n",
      "{'ʂ': 1, 'ʂː': 1, 'ʐ': 0, 'ʐː': 1}\n",
      "_______________\n",
      "ʐː\n",
      "{'ʂ': 1, 'ʂː': 1, 'ʐ': 1, 'ʐː': 0}\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.sign)\n",
    "    print(instance.similarities_uni_score)\n",
    "    print(\"_______________\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_int_pattern(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_consonant:\n",
    "            for _frozen_name in _instance.similarities_frozen_name_sign:\n",
    "                _sign = _instance.similarities_frozen_name_sign[_frozen_name]\n",
    "                _int = IpaDicts().sign2number[_sign]\n",
    "                try:\n",
    "                    _pattern = _instance.similarities_phone_features_pattern[_frozen_name]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                _instance.similarities_int_pattern[_int] = _pattern\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_int_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_ipasimilarities[10].similarities_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "{}\n",
      "b\n",
      "{2: 'same_cons', 3: 'palat', 4: 'palat', 5: 'prolong', 35: 'voice', 36: 'voice', 37: 'voice', 38: 'voice_prolong'}\n",
      "bʲ\n",
      "{2: 'palat', 3: 'same_cons', 4: 'prolong', 5: 'prolong', 35: 'prolong', 36: 'voice', 37: 'voice_prolong', 38: 'voice_prolong'}\n",
      "bʲː\n",
      "{2: 'voice_prolong', 3: 'prolong', 4: 'same_cons', 5: 'palat', 35: 'palat', 36: 'voice_prolong', 37: 'voice', 38: 'voice'}\n",
      "bː\n",
      "{2: 'prolong', 3: 'prolong', 4: 'palat', 5: 'same_cons', 35: 'voice_prolong', 36: 'voice_prolong', 37: 'voice_prolong', 38: 'voice'}\n",
      "d\n",
      "{6: 'same_cons', 7: 'palat', 8: 'palat', 9: 'prolong', 47: 'voice', 48: 'voice', 49: 'voice', 50: 'voice_prolong'}\n",
      "dʲ\n",
      "{6: 'palat', 7: 'same_cons', 8: 'prolong', 9: 'prolong', 47: 'prolong', 48: 'voice', 49: 'voice_prolong', 50: 'voice_prolong'}\n",
      "dʲː\n",
      "{6: 'voice_prolong', 7: 'prolong', 8: 'same_cons', 9: 'palat', 47: 'palat', 48: 'voice_prolong', 49: 'voice', 50: 'voice'}\n",
      "dː\n",
      "{6: 'prolong', 7: 'prolong', 8: 'palat', 9: 'same_cons', 47: 'voice_prolong', 48: 'voice_prolong', 49: 'voice_prolong', 50: 'voice'}\n",
      "d͡z\n",
      "{10: 'same_cons', 11: 'palat', 51: 'voice', 52: 'voice', 53: 'voice_prolong'}\n",
      "d͡zʲ\n",
      "{10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}\n",
      "e\n",
      "{}\n",
      "f\n",
      "{13: 'same_cons', 14: 'palat', 57: 'voice', 58: 'voice', 59: 'voice', 60: 'voice_prolong'}\n",
      "fʲ\n",
      "{13: 'palat', 14: 'same_cons', 57: 'same_cons', 58: 'voice', 59: 'voice_prolong', 60: 'voice_prolong'}\n",
      "i\n",
      "{}\n",
      "j\n",
      "{16: 'same_cons', 17: 'prolong'}\n",
      "jː\n",
      "{16: 'prolong', 17: 'same_cons'}\n",
      "k\n",
      "{18: 'same_cons', 19: 'palat', 20: 'palat', 21: 'prolong', 73: 'voice', 74: 'voice', 75: 'voice_prolong'}\n",
      "kʲ\n",
      "{18: 'palat', 19: 'same_cons', 20: 'prolong', 21: 'prolong', 73: 'prolong', 74: 'voice', 75: 'voice'}\n",
      "kʲː\n",
      "{18: 'voice', 19: 'prolong', 20: 'same_cons', 21: 'palat', 73: 'palat', 74: 'voice_prolong', 75: 'voice_prolong'}\n",
      "kː\n",
      "{18: 'prolong', 19: 'prolong', 20: 'palat', 21: 'same_cons', 73: 'voice_prolong', 74: 'voice_prolong', 75: 'voice'}\n",
      "lʲ\n",
      "{22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'}\n",
      "lʲː\n",
      "{22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'}\n",
      "lˠ\n",
      "{22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}\n",
      "lˠː\n",
      "{22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'}\n",
      "m\n",
      "{26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'}\n",
      "mʲ\n",
      "{26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'}\n",
      "mʲː\n",
      "{26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'}\n",
      "mː\n",
      "{26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'}\n",
      "n\n",
      "{30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'}\n",
      "nʲ\n",
      "{30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'}\n",
      "nʲː\n",
      "{30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'}\n",
      "nː\n",
      "{30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'}\n",
      "o\n",
      "{}\n",
      "p\n",
      "{2: 'voice', 3: 'voice', 4: 'voice', 5: 'voice_prolong', 35: 'same_cons', 36: 'palat', 37: 'palat', 38: 'prolong'}\n",
      "pʲ\n",
      "{2: 'prolong', 3: 'voice', 4: 'voice_prolong', 5: 'voice_prolong', 35: 'palat', 36: 'same_cons', 37: 'prolong', 38: 'prolong'}\n",
      "pʲː\n",
      "{2: 'prolong', 3: 'voice_prolong', 4: 'voice', 5: 'voice', 35: 'voice', 36: 'prolong', 37: 'same_cons', 38: 'palat'}\n",
      "pː\n",
      "{2: 'voice_prolong', 3: 'voice_prolong', 4: 'voice_prolong', 5: 'voice', 35: 'prolong', 36: 'prolong', 37: 'palat', 38: 'same_cons'}\n",
      "r\n",
      "{39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'}\n",
      "rʲ\n",
      "{39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'}\n",
      "rʲː\n",
      "{39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'}\n",
      "rː\n",
      "{39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'}\n",
      "s\n",
      "{43: 'same_cons', 44: 'palat', 45: 'palat', 46: 'prolong', 63: 'voice', 64: 'voice', 65: 'voice', 66: 'voice_prolong'}\n",
      "sʲ\n",
      "{43: 'palat', 44: 'same_cons', 45: 'prolong', 46: 'prolong', 63: 'prolong', 64: 'voice', 65: 'voice_prolong', 66: 'voice_prolong'}\n",
      "sʲː\n",
      "{43: 'voice_prolong', 44: 'prolong', 45: 'same_cons', 46: 'palat', 63: 'palat', 64: 'voice_prolong', 65: 'voice', 66: 'voice'}\n",
      "sː\n",
      "{43: 'prolong', 44: 'prolong', 45: 'palat', 46: 'same_cons', 63: 'voice_prolong', 64: 'voice_prolong', 65: 'voice_prolong', 66: 'voice'}\n",
      "t\n",
      "{6: 'voice', 7: 'voice', 8: 'voice', 9: 'voice_prolong', 47: 'same_cons', 48: 'palat', 49: 'palat', 50: 'prolong'}\n",
      "tʲ\n",
      "{6: 'prolong', 7: 'voice', 8: 'voice_prolong', 9: 'voice_prolong', 47: 'palat', 48: 'same_cons', 49: 'prolong', 50: 'prolong'}\n",
      "tʲː\n",
      "{6: 'prolong', 7: 'voice_prolong', 8: 'voice', 9: 'voice', 47: 'voice', 48: 'prolong', 49: 'same_cons', 50: 'palat'}\n",
      "tː\n",
      "{6: 'voice_prolong', 7: 'voice_prolong', 8: 'voice_prolong', 9: 'voice', 47: 'prolong', 48: 'prolong', 49: 'palat', 50: 'same_cons'}\n",
      "t͡s\n",
      "{10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'}\n",
      "t͡sʲ\n",
      "{10: 'prolong', 11: 'voice', 51: 'palat', 52: 'same_cons', 53: 'same_cons'}\n",
      "t͡sː\n",
      "{10: 'voice_prolong', 11: 'voice_prolong', 51: 'prolong', 52: 'prolong', 53: 'same_cons'}\n",
      "t͡ɕ\n",
      "{54: 'same_cons', 55: 'prolong'}\n",
      "t͡ɕː\n",
      "{54: 'prolong', 55: 'same_cons'}\n",
      "u\n",
      "{}\n",
      "v\n",
      "{13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}\n",
      "vʲ\n",
      "{13: 'prolong', 14: 'voice', 57: 'palat', 58: 'same_cons', 59: 'prolong', 60: 'prolong'}\n",
      "vʲː\n",
      "{13: 'prolong', 14: 'voice_prolong', 57: 'voice_prolong', 58: 'prolong', 59: 'same_cons', 60: 'palat'}\n",
      "vː\n",
      "{13: 'voice_prolong', 14: 'voice_prolong', 57: 'prolong', 58: 'prolong', 59: 'palat', 60: 'same_cons'}\n",
      "x\n",
      "{61: 'same_cons', 62: 'palat'}\n",
      "xʲ\n",
      "{61: 'palat', 62: 'same_cons'}\n",
      "z\n",
      "{43: 'voice', 44: 'voice', 45: 'voice', 46: 'voice_prolong', 63: 'same_cons', 64: 'palat', 65: 'palat', 66: 'prolong'}\n",
      "zʲ\n",
      "{43: 'prolong', 44: 'voice', 45: 'voice_prolong', 46: 'voice_prolong', 63: 'palat', 64: 'same_cons', 65: 'prolong', 66: 'prolong'}\n",
      "zʲː\n",
      "{43: 'prolong', 44: 'voice_prolong', 45: 'voice', 46: 'voice', 63: 'voice', 64: 'prolong', 65: 'same_cons', 66: 'palat'}\n",
      "zː\n",
      "{43: 'voice_prolong', 44: 'voice_prolong', 45: 'voice_prolong', 46: 'voice', 63: 'prolong', 64: 'prolong', 65: 'palat', 66: 'same_cons'}\n",
      "æ\n",
      "{}\n",
      "ɐ\n",
      "{}\n",
      "ɕ\n",
      "{69: 'same_cons', 70: 'prolong'}\n",
      "ɕː\n",
      "{69: 'prolong', 70: 'same_cons'}\n",
      "ə\n",
      "{}\n",
      "ɛ\n",
      "{}\n",
      "ɡ\n",
      "{18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}\n",
      "ɡʲ\n",
      "{18: 'prolong', 19: 'voice', 20: 'voice_prolong', 21: 'voice_prolong', 73: 'palat', 74: 'same_cons', 75: 'same_cons'}\n",
      "ɡː\n",
      "{18: 'voice_prolong', 19: 'voice_prolong', 20: 'voice_prolong', 21: 'voice', 73: 'prolong', 74: 'prolong', 75: 'same_cons'}\n",
      "ɨ\n",
      "{}\n",
      "ɪ\n",
      "{}\n",
      "ɵ\n",
      "{}\n",
      "ʂ\n",
      "{79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'}\n",
      "ʂː\n",
      "{79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'}\n",
      "ʈ͡ʂ\n",
      "{81: 'same_cons'}\n",
      "ʉ\n",
      "{}\n",
      "ʊ\n",
      "{}\n",
      "ʐ\n",
      "{79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'}\n",
      "ʐː\n",
      "{79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.sign)\n",
    "    print(instance.similarities_int_pattern)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_int_score(instances_ipasimilarities) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_consonant:\n",
    "            for _frozen_name in _instance.similarities_frozen_name_sign:\n",
    "                _sign = _instance.similarities_frozen_name_sign[_frozen_name]\n",
    "                _int = IpaDicts().sign2number[_sign]\n",
    "                try:\n",
    "                    _score = _instance.similarities_phone_features_score[_frozen_name]\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                _instance.similarities_int_score[_int] = _score\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_int_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 1, 3: 1, 4: 0, 5: 2, 35: 2, 36: 1, 37: 1, 38: 1}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_ipasimilarities[3].similarities_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'number': 4,\n 'root_phonetics': {'bilabial', 'plosive'},\n 'sign': bilabial consonant palatalized plosive voiced,\n 'similarities_sign': [bilabial consonant plosive voiced,\n  bilabial consonant palatalized plosive voiced,\n  bilabial consonant palatalized plosive voiced,\n  bilabial consonant plosive voiced,\n  bilabial consonant plosive voiceless,\n  bilabial consonant palatalized plosive voiceless,\n  bilabial consonant palatalized plosive voiceless,\n  bilabial consonant plosive voiceless],\n 'similarities_uni': ['b', 'bʲ', 'bʲː', 'bː', 'p', 'pʲ', 'pʲː', 'pː'],\n 'similarities_frozen_name_sign': {frozenset({'bilabial',\n             'consonant',\n             'plosive',\n             'voiced'}): bilabial consonant plosive voiced,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'voiced'}): bilabial consonant palatalized plosive voiced,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiced'}): bilabial consonant palatalized plosive voiced,\n  frozenset({'bilabial',\n             'consonant',\n             'plosive',\n             'prolonged',\n             'voiced'}): bilabial consonant plosive voiced,\n  frozenset({'bilabial',\n             'consonant',\n             'plosive',\n             'voiceless'}): bilabial consonant plosive voiceless,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'voiceless'}): bilabial consonant palatalized plosive voiceless,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiceless'}): bilabial consonant palatalized plosive voiceless,\n  frozenset({'bilabial',\n             'consonant',\n             'plosive',\n             'prolonged',\n             'voiceless'}): bilabial consonant plosive voiceless},\n 'similarities_phone_features_score': {frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiced'}): 0,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiceless'}): 1,\n  frozenset({'bilabial', 'consonant', 'plosive', 'prolonged', 'voiced'}): 2,\n  frozenset({'bilabial', 'consonant', 'palatalized', 'plosive', 'voiced'}): 1,\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'voiceless'}): 1},\n 'similarities_sign_score': {bilabial consonant plosive voiced: 1,\n  bilabial consonant palatalized plosive voiced: 1,\n  bilabial consonant palatalized plosive voiced: 0,\n  bilabial consonant plosive voiced: 2,\n  bilabial consonant plosive voiceless: 2,\n  bilabial consonant palatalized plosive voiceless: 1,\n  bilabial consonant palatalized plosive voiceless: 1,\n  bilabial consonant plosive voiceless: 1},\n 'similarities_uni_score': {'b': 1,\n  'bʲ': 1,\n  'bʲː': 0,\n  'bː': 2,\n  'p': 2,\n  'pʲ': 1,\n  'pʲː': 1,\n  'pː': 1},\n 'similarities_int_score': {2: 1,\n  3: 1,\n  4: 0,\n  5: 2,\n  35: 2,\n  36: 1,\n  37: 1,\n  38: 1},\n 'similarities_int_pattern': {2: 'voice_prolong',\n  3: 'prolong',\n  4: 'same_cons',\n  5: 'palat',\n  35: 'palat',\n  36: 'voice_prolong',\n  37: 'voice',\n  38: 'voice'},\n 'uni_dict_uni_score': {},\n 'similarities_phone_features_pattern': {frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiced'}): 'same_cons',\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'prolonged',\n             'voiceless'}): 'voice',\n  frozenset({'bilabial',\n             'consonant',\n             'plosive',\n             'prolonged',\n             'voiced'}): 'palat',\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'voiced'}): 'prolong',\n  frozenset({'bilabial',\n             'consonant',\n             'palatalized',\n             'plosive',\n             'voiceless'}): 'voice_prolong'},\n 'similarities_sign_pattern': {},\n 'int_dict_int_score': {},\n 'int_dict_int_pattern': {}}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(instances_ipasimilarities[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# vowels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_near_stressed_v"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class Vowels:\n",
    "    def __init__(self, instances_ipasimilarities):\n",
    "        self.instances_ipasimilrities = instances_ipasimilarities\n",
    "\n",
    "    @classmethod\n",
    "    def get_near_stressed_v(cls) -> dict[ipapy.ipachar, ipapy.ipachar]:\n",
    "        near_stressed_v = {\n",
    "            UNICODE_TO_IPA[\"a\"]: UNICODE_TO_IPA[\"æ\"],\n",
    "            UNICODE_TO_IPA[\"æ\"]: UNICODE_TO_IPA[\"a\"],\n",
    "            UNICODE_TO_IPA[\"ɛ\"]: UNICODE_TO_IPA[\"e\"],\n",
    "            UNICODE_TO_IPA[\"e\"]: UNICODE_TO_IPA[\"ɛ\"],\n",
    "            UNICODE_TO_IPA[\"i\"]: UNICODE_TO_IPA[\"ɨ\"],\n",
    "            UNICODE_TO_IPA[\"ɨ\"]: UNICODE_TO_IPA[\"i\"],\n",
    "            UNICODE_TO_IPA[\"o\"]: UNICODE_TO_IPA[\"ɵ\"],\n",
    "            UNICODE_TO_IPA[\"ɵ\"]: UNICODE_TO_IPA[\"o\"],\n",
    "            UNICODE_TO_IPA[\"u\"]: UNICODE_TO_IPA[\"ʉ\"],\n",
    "            UNICODE_TO_IPA[\"ʉ\"]: UNICODE_TO_IPA[\"u\"],\n",
    "        }\n",
    "        return near_stressed_v\n",
    "\n",
    "    def get_vowels_similarities_signs(self) -> list[IpaSimilarities]:\n",
    "        near_stressed_v = Vowels.get_near_stressed_v()\n",
    "        for _instance in instances_ipasimilarities:\n",
    "            if _instance.sign.is_vowel and not _instance.similarities_sign:\n",
    "                try:\n",
    "                    _instance.similarities_sign.append(near_stressed_v[_instance.sign])\n",
    "                    _instance.similarities_sign.append(_instance.sign)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "        return self.instances_ipasimilrities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## insert_vowels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def get_vowels_similarities_sign(instances_ipasimilarities):\n",
    "    instances_ipasimilarities = Vowels(instances_ipasimilarities).get_vowels_similarities_signs()\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_similarities_sign(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[front near-open unrounded vowel, front open unrounded vowel]\n",
      "[front open-mid unrounded vowel, close-mid front unrounded vowel]\n",
      "[central close unrounded vowel, close front unrounded vowel]\n",
      "[central close-mid rounded vowel, back close-mid rounded vowel]\n",
      "[central close rounded vowel, back close rounded vowel]\n",
      "[front open unrounded vowel, front near-open unrounded vowel]\n",
      "[]\n",
      "[]\n",
      "[close-mid front unrounded vowel, front open-mid unrounded vowel]\n",
      "[close front unrounded vowel, central close unrounded vowel]\n",
      "[]\n",
      "[back close-mid rounded vowel, central close-mid rounded vowel]\n",
      "[back close rounded vowel, central close rounded vowel]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print(instance.similarities_sign)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_vowel_sing_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def get_vowels_sign_pattern(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_vowel and _instance.similarities_sign:\n",
    "            for _ipa in _instance.similarities_sign:\n",
    "                if _instance.sign == _ipa:\n",
    "                    _instance.similarities_sign_pattern[_ipa] = \"same_stressed\"\n",
    "                else:\n",
    "                    _instance.similarities_sign_pattern[_ipa] = \"near_stressed\"\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_sign_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[front open unrounded vowel] 1 {front near-open unrounded vowel: 'near_stressed', front open unrounded vowel: 'same_stressed'}\n",
      "[close-mid front unrounded vowel] 12 {front open-mid unrounded vowel: 'near_stressed', close-mid front unrounded vowel: 'same_stressed'}\n",
      "[close front unrounded vowel] 15 {central close unrounded vowel: 'near_stressed', close front unrounded vowel: 'same_stressed'}\n",
      "[back close-mid rounded vowel] 34 {central close-mid rounded vowel: 'near_stressed', back close-mid rounded vowel: 'same_stressed'}\n",
      "[back close rounded vowel] 56 {central close rounded vowel: 'near_stressed', back close rounded vowel: 'same_stressed'}\n",
      "[front near-open unrounded vowel] 67 {front open unrounded vowel: 'near_stressed', front near-open unrounded vowel: 'same_stressed'}\n",
      "[central near-open unrounded vowel] 68 {}\n",
      "[central mid unrounded vowel] 71 {}\n",
      "[front open-mid unrounded vowel] 72 {close-mid front unrounded vowel: 'near_stressed', front open-mid unrounded vowel: 'same_stressed'}\n",
      "[central close unrounded vowel] 76 {close front unrounded vowel: 'near_stressed', central close unrounded vowel: 'same_stressed'}\n",
      "[near-close near-front unrounded vowel] 77 {}\n",
      "[central close-mid rounded vowel] 78 {back close-mid rounded vowel: 'near_stressed', central close-mid rounded vowel: 'same_stressed'}\n",
      "[central close rounded vowel] 82 {back close rounded vowel: 'near_stressed', central close rounded vowel: 'same_stressed'}\n",
      "[near-back near-close rounded vowel] 83 {}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print([instance.sign], instance.number, instance.similarities_sign_pattern)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_vowels_sing_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def get_vowels_sign_score(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_vowel and _instance.similarities_sign:\n",
    "            for _ipa in _instance.similarities_sign:\n",
    "                if _instance.sign == _ipa:\n",
    "                    _instance.similarities_sign_score[_ipa] = 0\n",
    "                else:\n",
    "                    _instance.similarities_sign_score[_ipa] = 1\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_sign_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[front open unrounded vowel] {front near-open unrounded vowel: 1, front open unrounded vowel: 0}\n",
      "[close-mid front unrounded vowel] {front open-mid unrounded vowel: 1, close-mid front unrounded vowel: 0}\n",
      "[close front unrounded vowel] {central close unrounded vowel: 1, close front unrounded vowel: 0}\n",
      "[back close-mid rounded vowel] {central close-mid rounded vowel: 1, back close-mid rounded vowel: 0}\n",
      "[back close rounded vowel] {central close rounded vowel: 1, back close rounded vowel: 0}\n",
      "[front near-open unrounded vowel] {front open unrounded vowel: 1, front near-open unrounded vowel: 0}\n",
      "[central near-open unrounded vowel] {}\n",
      "[central mid unrounded vowel] {}\n",
      "[front open-mid unrounded vowel] {close-mid front unrounded vowel: 1, front open-mid unrounded vowel: 0}\n",
      "[central close unrounded vowel] {close front unrounded vowel: 1, central close unrounded vowel: 0}\n",
      "[near-close near-front unrounded vowel] {}\n",
      "[central close-mid rounded vowel] {back close-mid rounded vowel: 1, central close-mid rounded vowel: 0}\n",
      "[central close rounded vowel] {back close rounded vowel: 1, central close rounded vowel: 0}\n",
      "[near-back near-close rounded vowel] {}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print([instance.sign], instance.similarities_sign_score)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_vowels_uni_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def get_vowels_uni_score(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_vowel and _instance.similarities_sign:\n",
    "            for key in _instance.similarities_sign_score:\n",
    "                _instance.similarities_uni_score[str(key)] = _instance.similarities_sign_score[key]\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_uni_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a {'æ': 1, 'a': 0}\n",
      "e {'ɛ': 1, 'e': 0}\n",
      "i {'ɨ': 1, 'i': 0}\n",
      "o {'ɵ': 1, 'o': 0}\n",
      "u {'ʉ': 1, 'u': 0}\n",
      "æ {'a': 1, 'æ': 0}\n",
      "ɐ {}\n",
      "ə {}\n",
      "ɛ {'e': 1, 'ɛ': 0}\n",
      "ɨ {'i': 1, 'ɨ': 0}\n",
      "ɪ {}\n",
      "ɵ {'o': 1, 'ɵ': 0}\n",
      "ʉ {'u': 1, 'ʉ': 0}\n",
      "ʊ {}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print(instance.sign, instance.similarities_uni_score)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_vowels_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_ipasimilarities[72].similarities_sign_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def get_vowels_int_pattern(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_vowel and _instance.similarities_sign:\n",
    "            for key in _instance.similarities_sign_pattern:\n",
    "                _int = IpaDicts().sign2number[key]\n",
    "                _pattern = _instance.similarities_sign_pattern[key]\n",
    "                _instance.similarities_int_pattern[_int] = _pattern\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_int_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a {67: 'near_stressed', 1: 'same_stressed'}\n",
      "e {72: 'near_stressed', 12: 'same_stressed'}\n",
      "i {76: 'near_stressed', 15: 'same_stressed'}\n",
      "o {78: 'near_stressed', 34: 'same_stressed'}\n",
      "u {82: 'near_stressed', 56: 'same_stressed'}\n",
      "æ {1: 'near_stressed', 67: 'same_stressed'}\n",
      "ɐ {}\n",
      "ə {}\n",
      "ɛ {12: 'near_stressed', 72: 'same_stressed'}\n",
      "ɨ {15: 'near_stressed', 76: 'same_stressed'}\n",
      "ɪ {}\n",
      "ɵ {34: 'near_stressed', 78: 'same_stressed'}\n",
      "ʉ {56: 'near_stressed', 82: 'same_stressed'}\n",
      "ʊ {}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print(instance.sign, instance.similarities_int_pattern)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_vowels_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def get_vowels_int_score(instances_ipasimilarities: list[IpaSimilarities]) -> list[IpaSimilarities]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.sign.is_vowel and _instance.similarities_sign:\n",
    "            for key in _instance.similarities_sign_score:\n",
    "                _instance.similarities_int_score[IpaDicts().sign2number[key]] = _instance.similarities_sign_score[key]\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = get_vowels_int_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a {67: 1, 1: 0}\n",
      "e {72: 1, 12: 0}\n",
      "i {76: 1, 15: 0}\n",
      "o {78: 1, 34: 0}\n",
      "u {82: 1, 56: 0}\n",
      "æ {1: 1, 67: 0}\n",
      "ɐ {}\n",
      "ə {}\n",
      "ɛ {12: 1, 72: 0}\n",
      "ɨ {15: 1, 76: 0}\n",
      "ɪ {}\n",
      "ɵ {34: 1, 78: 0}\n",
      "ʉ {56: 1, 82: 0}\n",
      "ʊ {}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.sign.is_vowel:\n",
    "        print(instance.sign, instance.similarities_int_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# make_uni_dict_uni_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def make_uni_dict_uni_score(instances_ipasimilarities: [IpaSimilarities]) -> dict[str, dict[str, int]]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.similarities_uni_score:\n",
    "            _instance.uni_dict_uni_score[str(_instance.sign)] = _instance.similarities_uni_score\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = make_uni_dict_uni_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# empty_items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def get_empty():\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if not instance.similarities_int_pattern:\n",
    "            print(instance.sign, instance.number)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## get_empty_items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def get_empty_items() -> list[int]:\n",
    "    empty_items: list[int] = []\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if not instance.similarities_int_score:\n",
    "            empty_items.append(instance.number)\n",
    "    return empty_items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68, 71, 77, 83]\n"
     ]
    }
   ],
   "source": [
    "empty_items = get_empty_items()\n",
    "print(empty_items)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set_empty_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def set_empty_int_pattern(instances_ipasimilarities: list[IpaSimilarities]) -> [IpaSimilarities]:\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if instance.number in empty_items:\n",
    "            instance.similarities_int_pattern = {}\n",
    "            instance.similarities_int_pattern[instance.number] = \"same_v\"\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = set_empty_int_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{68: 'same_v'}\n",
      "{71: 'same_v'}\n",
      "{77: 'same_v'}\n",
      "{83: 'same_v'}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if instance.number in empty_items:\n",
    "        print(instance.similarities_int_pattern)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{67: 'near_stressed', 1: 'same_stressed'}\n",
      "{2: 'same_cons', 3: 'palat', 4: 'palat', 5: 'prolong', 35: 'voice', 36: 'voice', 37: 'voice', 38: 'voice_prolong'}\n",
      "{2: 'palat', 3: 'same_cons', 4: 'prolong', 5: 'prolong', 35: 'prolong', 36: 'voice', 37: 'voice_prolong', 38: 'voice_prolong'}\n",
      "{2: 'voice_prolong', 3: 'prolong', 4: 'same_cons', 5: 'palat', 35: 'palat', 36: 'voice_prolong', 37: 'voice', 38: 'voice'}\n",
      "{2: 'prolong', 3: 'prolong', 4: 'palat', 5: 'same_cons', 35: 'voice_prolong', 36: 'voice_prolong', 37: 'voice_prolong', 38: 'voice'}\n",
      "{6: 'same_cons', 7: 'palat', 8: 'palat', 9: 'prolong', 47: 'voice', 48: 'voice', 49: 'voice', 50: 'voice_prolong'}\n",
      "{6: 'palat', 7: 'same_cons', 8: 'prolong', 9: 'prolong', 47: 'prolong', 48: 'voice', 49: 'voice_prolong', 50: 'voice_prolong'}\n",
      "{6: 'voice_prolong', 7: 'prolong', 8: 'same_cons', 9: 'palat', 47: 'palat', 48: 'voice_prolong', 49: 'voice', 50: 'voice'}\n",
      "{6: 'prolong', 7: 'prolong', 8: 'palat', 9: 'same_cons', 47: 'voice_prolong', 48: 'voice_prolong', 49: 'voice_prolong', 50: 'voice'}\n",
      "{10: 'same_cons', 11: 'palat', 51: 'voice', 52: 'voice', 53: 'voice_prolong'}\n",
      "{10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}\n",
      "{72: 'near_stressed', 12: 'same_stressed'}\n",
      "{13: 'same_cons', 14: 'palat', 57: 'voice', 58: 'voice', 59: 'voice', 60: 'voice_prolong'}\n",
      "{13: 'palat', 14: 'same_cons', 57: 'same_cons', 58: 'voice', 59: 'voice_prolong', 60: 'voice_prolong'}\n",
      "{76: 'near_stressed', 15: 'same_stressed'}\n",
      "{16: 'same_cons', 17: 'prolong'}\n",
      "{16: 'prolong', 17: 'same_cons'}\n",
      "{18: 'same_cons', 19: 'palat', 20: 'palat', 21: 'prolong', 73: 'voice', 74: 'voice', 75: 'voice_prolong'}\n",
      "{18: 'palat', 19: 'same_cons', 20: 'prolong', 21: 'prolong', 73: 'prolong', 74: 'voice', 75: 'voice'}\n",
      "{18: 'voice', 19: 'prolong', 20: 'same_cons', 21: 'palat', 73: 'palat', 74: 'voice_prolong', 75: 'voice_prolong'}\n",
      "{18: 'prolong', 19: 'prolong', 20: 'palat', 21: 'same_cons', 73: 'voice_prolong', 74: 'voice_prolong', 75: 'voice'}\n",
      "{22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'}\n",
      "{22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'}\n",
      "{22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}\n",
      "{22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'}\n",
      "{26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'}\n",
      "{26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'}\n",
      "{26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'}\n",
      "{26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'}\n",
      "{30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'}\n",
      "{30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'}\n",
      "{30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'}\n",
      "{30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'}\n",
      "{78: 'near_stressed', 34: 'same_stressed'}\n",
      "{2: 'voice', 3: 'voice', 4: 'voice', 5: 'voice_prolong', 35: 'same_cons', 36: 'palat', 37: 'palat', 38: 'prolong'}\n",
      "{2: 'prolong', 3: 'voice', 4: 'voice_prolong', 5: 'voice_prolong', 35: 'palat', 36: 'same_cons', 37: 'prolong', 38: 'prolong'}\n",
      "{2: 'prolong', 3: 'voice_prolong', 4: 'voice', 5: 'voice', 35: 'voice', 36: 'prolong', 37: 'same_cons', 38: 'palat'}\n",
      "{2: 'voice_prolong', 3: 'voice_prolong', 4: 'voice_prolong', 5: 'voice', 35: 'prolong', 36: 'prolong', 37: 'palat', 38: 'same_cons'}\n",
      "{39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'}\n",
      "{39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'}\n",
      "{39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'}\n",
      "{39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'}\n",
      "{43: 'same_cons', 44: 'palat', 45: 'palat', 46: 'prolong', 63: 'voice', 64: 'voice', 65: 'voice', 66: 'voice_prolong'}\n",
      "{43: 'palat', 44: 'same_cons', 45: 'prolong', 46: 'prolong', 63: 'prolong', 64: 'voice', 65: 'voice_prolong', 66: 'voice_prolong'}\n",
      "{43: 'voice_prolong', 44: 'prolong', 45: 'same_cons', 46: 'palat', 63: 'palat', 64: 'voice_prolong', 65: 'voice', 66: 'voice'}\n",
      "{43: 'prolong', 44: 'prolong', 45: 'palat', 46: 'same_cons', 63: 'voice_prolong', 64: 'voice_prolong', 65: 'voice_prolong', 66: 'voice'}\n",
      "{6: 'voice', 7: 'voice', 8: 'voice', 9: 'voice_prolong', 47: 'same_cons', 48: 'palat', 49: 'palat', 50: 'prolong'}\n",
      "{6: 'prolong', 7: 'voice', 8: 'voice_prolong', 9: 'voice_prolong', 47: 'palat', 48: 'same_cons', 49: 'prolong', 50: 'prolong'}\n",
      "{6: 'prolong', 7: 'voice_prolong', 8: 'voice', 9: 'voice', 47: 'voice', 48: 'prolong', 49: 'same_cons', 50: 'palat'}\n",
      "{6: 'voice_prolong', 7: 'voice_prolong', 8: 'voice_prolong', 9: 'voice', 47: 'prolong', 48: 'prolong', 49: 'palat', 50: 'same_cons'}\n",
      "{10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'}\n",
      "{10: 'prolong', 11: 'voice', 51: 'palat', 52: 'same_cons', 53: 'same_cons'}\n",
      "{10: 'voice_prolong', 11: 'voice_prolong', 51: 'prolong', 52: 'prolong', 53: 'same_cons'}\n",
      "{54: 'same_cons', 55: 'prolong'}\n",
      "{54: 'prolong', 55: 'same_cons'}\n",
      "{82: 'near_stressed', 56: 'same_stressed'}\n",
      "{13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}\n",
      "{13: 'prolong', 14: 'voice', 57: 'palat', 58: 'same_cons', 59: 'prolong', 60: 'prolong'}\n",
      "{13: 'prolong', 14: 'voice_prolong', 57: 'voice_prolong', 58: 'prolong', 59: 'same_cons', 60: 'palat'}\n",
      "{13: 'voice_prolong', 14: 'voice_prolong', 57: 'prolong', 58: 'prolong', 59: 'palat', 60: 'same_cons'}\n",
      "{61: 'same_cons', 62: 'palat'}\n",
      "{61: 'palat', 62: 'same_cons'}\n",
      "{43: 'voice', 44: 'voice', 45: 'voice', 46: 'voice_prolong', 63: 'same_cons', 64: 'palat', 65: 'palat', 66: 'prolong'}\n",
      "{43: 'prolong', 44: 'voice', 45: 'voice_prolong', 46: 'voice_prolong', 63: 'palat', 64: 'same_cons', 65: 'prolong', 66: 'prolong'}\n",
      "{43: 'prolong', 44: 'voice_prolong', 45: 'voice', 46: 'voice', 63: 'voice', 64: 'prolong', 65: 'same_cons', 66: 'palat'}\n",
      "{43: 'voice_prolong', 44: 'voice_prolong', 45: 'voice_prolong', 46: 'voice', 63: 'prolong', 64: 'prolong', 65: 'palat', 66: 'same_cons'}\n",
      "{1: 'near_stressed', 67: 'same_stressed'}\n",
      "{68: 'same_v'}\n",
      "{69: 'same_cons', 70: 'prolong'}\n",
      "{69: 'prolong', 70: 'same_cons'}\n",
      "{71: 'same_v'}\n",
      "{12: 'near_stressed', 72: 'same_stressed'}\n",
      "{18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}\n",
      "{18: 'prolong', 19: 'voice', 20: 'voice_prolong', 21: 'voice_prolong', 73: 'palat', 74: 'same_cons', 75: 'same_cons'}\n",
      "{18: 'voice_prolong', 19: 'voice_prolong', 20: 'voice_prolong', 21: 'voice', 73: 'prolong', 74: 'prolong', 75: 'same_cons'}\n",
      "{15: 'near_stressed', 76: 'same_stressed'}\n",
      "{77: 'same_v'}\n",
      "{34: 'near_stressed', 78: 'same_stressed'}\n",
      "{79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'}\n",
      "{79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'}\n",
      "{81: 'same_cons'}\n",
      "{56: 'near_stressed', 82: 'same_stressed'}\n",
      "{83: 'same_v'}\n",
      "{79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'}\n",
      "{79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.similarities_int_pattern)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set_empty_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def set_empty_int_score(instances_ipasimilarities: list[IpaSimilarities]) -> list[dict[int, int]]:\n",
    "    for instance in instances_ipasimilarities:\n",
    "        if instance.number in empty_items:\n",
    "            instance.similarities_int_score = {}\n",
    "            instance.similarities_int_score[instance.number] = 0\n",
    "    return instances_ipasimilarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = set_empty_int_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{67: 1, 1: 0}\n",
      "{2: 0, 3: 2, 4: 2, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{2: 2, 3: 0, 4: 1, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{2: 1, 3: 1, 4: 0, 5: 2, 35: 2, 36: 1, 37: 1, 38: 1}\n",
      "{2: 1, 3: 1, 4: 2, 5: 0, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{6: 0, 7: 2, 8: 2, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{6: 2, 7: 0, 8: 1, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{6: 1, 7: 1, 8: 0, 9: 2, 47: 2, 48: 1, 49: 1, 50: 1}\n",
      "{6: 1, 7: 1, 8: 2, 9: 0, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{10: 0, 11: 2, 51: 1, 52: 1, 53: 1}\n",
      "{10: 2, 11: 0, 51: 0, 52: 1, 53: 1}\n",
      "{72: 1, 12: 0}\n",
      "{13: 0, 14: 2, 57: 1, 58: 1, 59: 1, 60: 1}\n",
      "{13: 2, 14: 0, 57: 0, 58: 1, 59: 1, 60: 1}\n",
      "{76: 1, 15: 0}\n",
      "{16: 0, 17: 1}\n",
      "{16: 1, 17: 0}\n",
      "{18: 0, 19: 2, 20: 2, 21: 1, 73: 1, 74: 1, 75: 1}\n",
      "{18: 2, 19: 0, 20: 1, 21: 1, 73: 1, 74: 1, 75: 1}\n",
      "{18: 1, 19: 1, 20: 0, 21: 2, 73: 2, 74: 1, 75: 1}\n",
      "{18: 1, 19: 1, 20: 2, 21: 0, 73: 1, 74: 1, 75: 1}\n",
      "{22: 0, 23: 1, 24: 2, 25: 2}\n",
      "{22: 1, 23: 0, 24: 0, 25: 2}\n",
      "{22: 2, 23: 2, 24: 0, 25: 1}\n",
      "{22: 1, 23: 2, 24: 1, 25: 0}\n",
      "{26: 0, 27: 2, 28: 2, 29: 1}\n",
      "{26: 2, 27: 0, 28: 1, 29: 1}\n",
      "{26: 1, 27: 1, 28: 0, 29: 2}\n",
      "{26: 1, 27: 1, 28: 2, 29: 0}\n",
      "{30: 0, 31: 2, 32: 2, 33: 1}\n",
      "{30: 2, 31: 0, 32: 1, 33: 1}\n",
      "{30: 1, 31: 1, 32: 0, 33: 2}\n",
      "{30: 1, 31: 1, 32: 2, 33: 0}\n",
      "{78: 1, 34: 0}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 0, 36: 2, 37: 2, 38: 1}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 2, 36: 0, 37: 1, 38: 1}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 0, 38: 2}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 2, 38: 0}\n",
      "{39: 0, 40: 2, 41: 2, 42: 1}\n",
      "{39: 2, 40: 0, 41: 1, 42: 1}\n",
      "{39: 1, 40: 1, 41: 0, 42: 2}\n",
      "{39: 1, 40: 1, 41: 2, 42: 0}\n",
      "{43: 0, 44: 2, 45: 2, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{43: 2, 44: 0, 45: 1, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{43: 1, 44: 1, 45: 0, 46: 2, 63: 2, 64: 1, 65: 1, 66: 1}\n",
      "{43: 1, 44: 1, 45: 2, 46: 0, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 0, 48: 2, 49: 2, 50: 1}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 2, 48: 0, 49: 1, 50: 1}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 0, 50: 2}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 2, 50: 0}\n",
      "{10: 1, 11: 1, 51: 0, 52: 2, 53: 1}\n",
      "{10: 1, 11: 1, 51: 2, 52: 0, 53: 0}\n",
      "{10: 1, 11: 1, 51: 1, 52: 1, 53: 0}\n",
      "{54: 0, 55: 1}\n",
      "{54: 1, 55: 0}\n",
      "{82: 1, 56: 0}\n",
      "{13: 1, 14: 1, 57: 0, 58: 2, 59: 2, 60: 1}\n",
      "{13: 1, 14: 1, 57: 2, 58: 0, 59: 1, 60: 1}\n",
      "{13: 1, 14: 1, 57: 1, 58: 1, 59: 0, 60: 2}\n",
      "{13: 1, 14: 1, 57: 1, 58: 1, 59: 2, 60: 0}\n",
      "{61: 0, 62: 2}\n",
      "{61: 2, 62: 0}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 0, 64: 2, 65: 2, 66: 1}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 2, 64: 0, 65: 1, 66: 1}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 0, 66: 2}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 2, 66: 0}\n",
      "{1: 1, 67: 0}\n",
      "{68: 0}\n",
      "{69: 0, 70: 1}\n",
      "{69: 1, 70: 0}\n",
      "{71: 0}\n",
      "{12: 1, 72: 0}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 0, 74: 2, 75: 1}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 2, 74: 0, 75: 0}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 1, 74: 1, 75: 0}\n",
      "{15: 1, 76: 0}\n",
      "{77: 0}\n",
      "{34: 1, 78: 0}\n",
      "{79: 0, 80: 1, 84: 1, 85: 1}\n",
      "{79: 1, 80: 0, 84: 1, 85: 1}\n",
      "{81: 0}\n",
      "{56: 1, 82: 0}\n",
      "{83: 0}\n",
      "{79: 1, 80: 1, 84: 0, 85: 1}\n",
      "{79: 1, 80: 1, 84: 1, 85: 0}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.similarities_int_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_empty_items()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# get_instance_by_number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def get_instance_by_number(number: int) -> IpaSimilarities:\n",
    "    instance = [instance for instance in instances_ipasimilarities if instance.number == number]\n",
    "    return instance[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alveolar', 'lateral-approximant'}\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "{'alveolar', 'lateral-approximant'}\n",
      "{'alveolar', 'lateral-approximant'}\n"
     ]
    }
   ],
   "source": [
    "for i in range(22, 26):\n",
    "    my_instance = get_instance_by_number(i)\n",
    "    print(my_instance.root_phonetics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voiced alveolar lateral-approximant consonant palatalized\n",
      "voiced alveolar lateral-approximant consonant palatalized prolonged\n",
      "voiced alveolar lateral-approximant velarized consonant\n",
      "voiced alveolar lateral-approximant velarized consonant prolonged\n"
     ]
    }
   ],
   "source": [
    "for i in range(22, 26):\n",
    "    my_instance = get_instance_by_number(i)\n",
    "    print(my_instance.sign.name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lˠ voiced alveolar lateral-approximant velarized consonant\n",
      "lˠː voiced alveolar lateral-approximant velarized consonant prolonged\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    if \"velarized\" in instance.sign.name:\n",
    "        print(instance.sign, instance.sign.name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## make_int_dict_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "{2: 'voice_prolong',\n 3: 'prolong',\n 4: 'same_cons',\n 5: 'palat',\n 35: 'palat',\n 36: 'voice_prolong',\n 37: 'voice',\n 38: 'voice'}"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances_ipasimilarities[3].similarities_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def make_int_dict_int_pattern(instances_ipasimilarities: [IpaSimilarities]) -> dict[int, dict[int, int]]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.similarities_int_pattern:\n",
    "            _instance.int_dict_int_pattern[IpaDicts().sign2number[_instance.sign]] = _instance.similarities_int_pattern\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = make_int_dict_int_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {67: 'near_stressed', 1: 'same_stressed'}}\n",
      "{2: {2: 'same_cons', 3: 'palat', 4: 'palat', 5: 'prolong', 35: 'voice', 36: 'voice', 37: 'voice', 38: 'voice_prolong'}}\n",
      "{3: {2: 'palat', 3: 'same_cons', 4: 'prolong', 5: 'prolong', 35: 'prolong', 36: 'voice', 37: 'voice_prolong', 38: 'voice_prolong'}}\n",
      "{4: {2: 'voice_prolong', 3: 'prolong', 4: 'same_cons', 5: 'palat', 35: 'palat', 36: 'voice_prolong', 37: 'voice', 38: 'voice'}}\n",
      "{5: {2: 'prolong', 3: 'prolong', 4: 'palat', 5: 'same_cons', 35: 'voice_prolong', 36: 'voice_prolong', 37: 'voice_prolong', 38: 'voice'}}\n",
      "{6: {6: 'same_cons', 7: 'palat', 8: 'palat', 9: 'prolong', 47: 'voice', 48: 'voice', 49: 'voice', 50: 'voice_prolong'}}\n",
      "{7: {6: 'palat', 7: 'same_cons', 8: 'prolong', 9: 'prolong', 47: 'prolong', 48: 'voice', 49: 'voice_prolong', 50: 'voice_prolong'}}\n",
      "{8: {6: 'voice_prolong', 7: 'prolong', 8: 'same_cons', 9: 'palat', 47: 'palat', 48: 'voice_prolong', 49: 'voice', 50: 'voice'}}\n",
      "{9: {6: 'prolong', 7: 'prolong', 8: 'palat', 9: 'same_cons', 47: 'voice_prolong', 48: 'voice_prolong', 49: 'voice_prolong', 50: 'voice'}}\n",
      "{10: {10: 'same_cons', 11: 'palat', 51: 'voice', 52: 'voice', 53: 'voice_prolong'}}\n",
      "{11: {10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}}\n",
      "{12: {72: 'near_stressed', 12: 'same_stressed'}}\n",
      "{13: {13: 'same_cons', 14: 'palat', 57: 'voice', 58: 'voice', 59: 'voice', 60: 'voice_prolong'}}\n",
      "{14: {13: 'palat', 14: 'same_cons', 57: 'same_cons', 58: 'voice', 59: 'voice_prolong', 60: 'voice_prolong'}}\n",
      "{15: {76: 'near_stressed', 15: 'same_stressed'}}\n",
      "{16: {16: 'same_cons', 17: 'prolong'}}\n",
      "{17: {16: 'prolong', 17: 'same_cons'}}\n",
      "{18: {18: 'same_cons', 19: 'palat', 20: 'palat', 21: 'prolong', 73: 'voice', 74: 'voice', 75: 'voice_prolong'}}\n",
      "{19: {18: 'palat', 19: 'same_cons', 20: 'prolong', 21: 'prolong', 73: 'prolong', 74: 'voice', 75: 'voice'}}\n",
      "{20: {18: 'voice', 19: 'prolong', 20: 'same_cons', 21: 'palat', 73: 'palat', 74: 'voice_prolong', 75: 'voice_prolong'}}\n",
      "{21: {18: 'prolong', 19: 'prolong', 20: 'palat', 21: 'same_cons', 73: 'voice_prolong', 74: 'voice_prolong', 75: 'voice'}}\n",
      "{22: {22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'}}\n",
      "{23: {22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'}}\n",
      "{24: {22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}}\n",
      "{25: {22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'}}\n",
      "{26: {26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'}}\n",
      "{27: {26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'}}\n",
      "{28: {26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'}}\n",
      "{29: {26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'}}\n",
      "{30: {30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'}}\n",
      "{31: {30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'}}\n",
      "{32: {30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'}}\n",
      "{33: {30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'}}\n",
      "{34: {78: 'near_stressed', 34: 'same_stressed'}}\n",
      "{35: {2: 'voice', 3: 'voice', 4: 'voice', 5: 'voice_prolong', 35: 'same_cons', 36: 'palat', 37: 'palat', 38: 'prolong'}}\n",
      "{36: {2: 'prolong', 3: 'voice', 4: 'voice_prolong', 5: 'voice_prolong', 35: 'palat', 36: 'same_cons', 37: 'prolong', 38: 'prolong'}}\n",
      "{37: {2: 'prolong', 3: 'voice_prolong', 4: 'voice', 5: 'voice', 35: 'voice', 36: 'prolong', 37: 'same_cons', 38: 'palat'}}\n",
      "{38: {2: 'voice_prolong', 3: 'voice_prolong', 4: 'voice_prolong', 5: 'voice', 35: 'prolong', 36: 'prolong', 37: 'palat', 38: 'same_cons'}}\n",
      "{39: {39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'}}\n",
      "{40: {39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'}}\n",
      "{41: {39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'}}\n",
      "{42: {39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'}}\n",
      "{43: {43: 'same_cons', 44: 'palat', 45: 'palat', 46: 'prolong', 63: 'voice', 64: 'voice', 65: 'voice', 66: 'voice_prolong'}}\n",
      "{44: {43: 'palat', 44: 'same_cons', 45: 'prolong', 46: 'prolong', 63: 'prolong', 64: 'voice', 65: 'voice_prolong', 66: 'voice_prolong'}}\n",
      "{45: {43: 'voice_prolong', 44: 'prolong', 45: 'same_cons', 46: 'palat', 63: 'palat', 64: 'voice_prolong', 65: 'voice', 66: 'voice'}}\n",
      "{46: {43: 'prolong', 44: 'prolong', 45: 'palat', 46: 'same_cons', 63: 'voice_prolong', 64: 'voice_prolong', 65: 'voice_prolong', 66: 'voice'}}\n",
      "{47: {6: 'voice', 7: 'voice', 8: 'voice', 9: 'voice_prolong', 47: 'same_cons', 48: 'palat', 49: 'palat', 50: 'prolong'}}\n",
      "{48: {6: 'prolong', 7: 'voice', 8: 'voice_prolong', 9: 'voice_prolong', 47: 'palat', 48: 'same_cons', 49: 'prolong', 50: 'prolong'}}\n",
      "{49: {6: 'prolong', 7: 'voice_prolong', 8: 'voice', 9: 'voice', 47: 'voice', 48: 'prolong', 49: 'same_cons', 50: 'palat'}}\n",
      "{50: {6: 'voice_prolong', 7: 'voice_prolong', 8: 'voice_prolong', 9: 'voice', 47: 'prolong', 48: 'prolong', 49: 'palat', 50: 'same_cons'}}\n",
      "{51: {10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'}}\n",
      "{52: {10: 'prolong', 11: 'voice', 51: 'palat', 52: 'same_cons', 53: 'same_cons'}}\n",
      "{53: {10: 'voice_prolong', 11: 'voice_prolong', 51: 'prolong', 52: 'prolong', 53: 'same_cons'}}\n",
      "{54: {54: 'same_cons', 55: 'prolong'}}\n",
      "{55: {54: 'prolong', 55: 'same_cons'}}\n",
      "{56: {82: 'near_stressed', 56: 'same_stressed'}}\n",
      "{57: {13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}}\n",
      "{58: {13: 'prolong', 14: 'voice', 57: 'palat', 58: 'same_cons', 59: 'prolong', 60: 'prolong'}}\n",
      "{59: {13: 'prolong', 14: 'voice_prolong', 57: 'voice_prolong', 58: 'prolong', 59: 'same_cons', 60: 'palat'}}\n",
      "{60: {13: 'voice_prolong', 14: 'voice_prolong', 57: 'prolong', 58: 'prolong', 59: 'palat', 60: 'same_cons'}}\n",
      "{61: {61: 'same_cons', 62: 'palat'}}\n",
      "{62: {61: 'palat', 62: 'same_cons'}}\n",
      "{63: {43: 'voice', 44: 'voice', 45: 'voice', 46: 'voice_prolong', 63: 'same_cons', 64: 'palat', 65: 'palat', 66: 'prolong'}}\n",
      "{64: {43: 'prolong', 44: 'voice', 45: 'voice_prolong', 46: 'voice_prolong', 63: 'palat', 64: 'same_cons', 65: 'prolong', 66: 'prolong'}}\n",
      "{65: {43: 'prolong', 44: 'voice_prolong', 45: 'voice', 46: 'voice', 63: 'voice', 64: 'prolong', 65: 'same_cons', 66: 'palat'}}\n",
      "{66: {43: 'voice_prolong', 44: 'voice_prolong', 45: 'voice_prolong', 46: 'voice', 63: 'prolong', 64: 'prolong', 65: 'palat', 66: 'same_cons'}}\n",
      "{67: {1: 'near_stressed', 67: 'same_stressed'}}\n",
      "{68: {68: 'same_v'}}\n",
      "{69: {69: 'same_cons', 70: 'prolong'}}\n",
      "{70: {69: 'prolong', 70: 'same_cons'}}\n",
      "{71: {71: 'same_v'}}\n",
      "{72: {12: 'near_stressed', 72: 'same_stressed'}}\n",
      "{73: {18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}}\n",
      "{74: {18: 'prolong', 19: 'voice', 20: 'voice_prolong', 21: 'voice_prolong', 73: 'palat', 74: 'same_cons', 75: 'same_cons'}}\n",
      "{75: {18: 'voice_prolong', 19: 'voice_prolong', 20: 'voice_prolong', 21: 'voice', 73: 'prolong', 74: 'prolong', 75: 'same_cons'}}\n",
      "{76: {15: 'near_stressed', 76: 'same_stressed'}}\n",
      "{77: {77: 'same_v'}}\n",
      "{78: {34: 'near_stressed', 78: 'same_stressed'}}\n",
      "{79: {79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'}}\n",
      "{80: {79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'}}\n",
      "{81: {81: 'same_cons'}}\n",
      "{82: {56: 'near_stressed', 82: 'same_stressed'}}\n",
      "{83: {83: 'same_v'}}\n",
      "{84: {79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'}}\n",
      "{85: {79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}}\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.int_dict_int_pattern)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## make_int_dict_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def make_int_dict_int_score(instances_ipasimilarities: [IpaSimilarities]) -> dict[int, dict[int, int]]:\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.similarities_int_score:\n",
    "            _instance.int_dict_int_score[IpaDicts().sign2number[_instance.sign]] = _instance.similarities_int_score\n",
    "    return instances_ipasimilarities\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "instances_ipasimilarities = make_int_dict_int_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "{1: {67: 'near_stressed', 1: 'same_stressed'}}\n",
      "{67: 1, 1: 0}\n",
      "{1: {67: 1, 1: 0}}\n",
      "{1: {67: 'near_stressed', 1: 'same_stressed'}}\n",
      "______________\n",
      "b 2\n",
      "{2: {2: 'same_cons', 3: 'palat', 4: 'palat', 5: 'prolong', 35: 'voice', 36: 'voice', 37: 'voice', 38: 'voice_prolong'}}\n",
      "{2: 0, 3: 2, 4: 2, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{2: {2: 0, 3: 2, 4: 2, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}}\n",
      "{2: {2: 'same_cons', 3: 'palat', 4: 'palat', 5: 'prolong', 35: 'voice', 36: 'voice', 37: 'voice', 38: 'voice_prolong'}}\n",
      "______________\n",
      "bʲ 3\n",
      "{3: {2: 'palat', 3: 'same_cons', 4: 'prolong', 5: 'prolong', 35: 'prolong', 36: 'voice', 37: 'voice_prolong', 38: 'voice_prolong'}}\n",
      "{2: 2, 3: 0, 4: 1, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{3: {2: 2, 3: 0, 4: 1, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1}}\n",
      "{3: {2: 'palat', 3: 'same_cons', 4: 'prolong', 5: 'prolong', 35: 'prolong', 36: 'voice', 37: 'voice_prolong', 38: 'voice_prolong'}}\n",
      "______________\n",
      "bʲː 4\n",
      "{4: {2: 'voice_prolong', 3: 'prolong', 4: 'same_cons', 5: 'palat', 35: 'palat', 36: 'voice_prolong', 37: 'voice', 38: 'voice'}}\n",
      "{2: 1, 3: 1, 4: 0, 5: 2, 35: 2, 36: 1, 37: 1, 38: 1}\n",
      "{4: {2: 1, 3: 1, 4: 0, 5: 2, 35: 2, 36: 1, 37: 1, 38: 1}}\n",
      "{4: {2: 'voice_prolong', 3: 'prolong', 4: 'same_cons', 5: 'palat', 35: 'palat', 36: 'voice_prolong', 37: 'voice', 38: 'voice'}}\n",
      "______________\n",
      "bː 5\n",
      "{5: {2: 'prolong', 3: 'prolong', 4: 'palat', 5: 'same_cons', 35: 'voice_prolong', 36: 'voice_prolong', 37: 'voice_prolong', 38: 'voice'}}\n",
      "{2: 1, 3: 1, 4: 2, 5: 0, 35: 1, 36: 1, 37: 1, 38: 1}\n",
      "{5: {2: 1, 3: 1, 4: 2, 5: 0, 35: 1, 36: 1, 37: 1, 38: 1}}\n",
      "{5: {2: 'prolong', 3: 'prolong', 4: 'palat', 5: 'same_cons', 35: 'voice_prolong', 36: 'voice_prolong', 37: 'voice_prolong', 38: 'voice'}}\n",
      "______________\n",
      "d 6\n",
      "{6: {6: 'same_cons', 7: 'palat', 8: 'palat', 9: 'prolong', 47: 'voice', 48: 'voice', 49: 'voice', 50: 'voice_prolong'}}\n",
      "{6: 0, 7: 2, 8: 2, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{6: {6: 0, 7: 2, 8: 2, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}}\n",
      "{6: {6: 'same_cons', 7: 'palat', 8: 'palat', 9: 'prolong', 47: 'voice', 48: 'voice', 49: 'voice', 50: 'voice_prolong'}}\n",
      "______________\n",
      "dʲ 7\n",
      "{7: {6: 'palat', 7: 'same_cons', 8: 'prolong', 9: 'prolong', 47: 'prolong', 48: 'voice', 49: 'voice_prolong', 50: 'voice_prolong'}}\n",
      "{6: 2, 7: 0, 8: 1, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{7: {6: 2, 7: 0, 8: 1, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1}}\n",
      "{7: {6: 'palat', 7: 'same_cons', 8: 'prolong', 9: 'prolong', 47: 'prolong', 48: 'voice', 49: 'voice_prolong', 50: 'voice_prolong'}}\n",
      "______________\n",
      "dʲː 8\n",
      "{8: {6: 'voice_prolong', 7: 'prolong', 8: 'same_cons', 9: 'palat', 47: 'palat', 48: 'voice_prolong', 49: 'voice', 50: 'voice'}}\n",
      "{6: 1, 7: 1, 8: 0, 9: 2, 47: 2, 48: 1, 49: 1, 50: 1}\n",
      "{8: {6: 1, 7: 1, 8: 0, 9: 2, 47: 2, 48: 1, 49: 1, 50: 1}}\n",
      "{8: {6: 'voice_prolong', 7: 'prolong', 8: 'same_cons', 9: 'palat', 47: 'palat', 48: 'voice_prolong', 49: 'voice', 50: 'voice'}}\n",
      "______________\n",
      "dː 9\n",
      "{9: {6: 'prolong', 7: 'prolong', 8: 'palat', 9: 'same_cons', 47: 'voice_prolong', 48: 'voice_prolong', 49: 'voice_prolong', 50: 'voice'}}\n",
      "{6: 1, 7: 1, 8: 2, 9: 0, 47: 1, 48: 1, 49: 1, 50: 1}\n",
      "{9: {6: 1, 7: 1, 8: 2, 9: 0, 47: 1, 48: 1, 49: 1, 50: 1}}\n",
      "{9: {6: 'prolong', 7: 'prolong', 8: 'palat', 9: 'same_cons', 47: 'voice_prolong', 48: 'voice_prolong', 49: 'voice_prolong', 50: 'voice'}}\n",
      "______________\n",
      "d͡z 10\n",
      "{10: {10: 'same_cons', 11: 'palat', 51: 'voice', 52: 'voice', 53: 'voice_prolong'}}\n",
      "{10: 0, 11: 2, 51: 1, 52: 1, 53: 1}\n",
      "{10: {10: 0, 11: 2, 51: 1, 52: 1, 53: 1}}\n",
      "{10: {10: 'same_cons', 11: 'palat', 51: 'voice', 52: 'voice', 53: 'voice_prolong'}}\n",
      "______________\n",
      "d͡zʲ 11\n",
      "{11: {10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}}\n",
      "{10: 2, 11: 0, 51: 0, 52: 1, 53: 1}\n",
      "{11: {10: 2, 11: 0, 51: 0, 52: 1, 53: 1}}\n",
      "{11: {10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'}}\n",
      "______________\n",
      "e 12\n",
      "{12: {72: 'near_stressed', 12: 'same_stressed'}}\n",
      "{72: 1, 12: 0}\n",
      "{12: {72: 1, 12: 0}}\n",
      "{12: {72: 'near_stressed', 12: 'same_stressed'}}\n",
      "______________\n",
      "f 13\n",
      "{13: {13: 'same_cons', 14: 'palat', 57: 'voice', 58: 'voice', 59: 'voice', 60: 'voice_prolong'}}\n",
      "{13: 0, 14: 2, 57: 1, 58: 1, 59: 1, 60: 1}\n",
      "{13: {13: 0, 14: 2, 57: 1, 58: 1, 59: 1, 60: 1}}\n",
      "{13: {13: 'same_cons', 14: 'palat', 57: 'voice', 58: 'voice', 59: 'voice', 60: 'voice_prolong'}}\n",
      "______________\n",
      "fʲ 14\n",
      "{14: {13: 'palat', 14: 'same_cons', 57: 'same_cons', 58: 'voice', 59: 'voice_prolong', 60: 'voice_prolong'}}\n",
      "{13: 2, 14: 0, 57: 0, 58: 1, 59: 1, 60: 1}\n",
      "{14: {13: 2, 14: 0, 57: 0, 58: 1, 59: 1, 60: 1}}\n",
      "{14: {13: 'palat', 14: 'same_cons', 57: 'same_cons', 58: 'voice', 59: 'voice_prolong', 60: 'voice_prolong'}}\n",
      "______________\n",
      "i 15\n",
      "{15: {76: 'near_stressed', 15: 'same_stressed'}}\n",
      "{76: 1, 15: 0}\n",
      "{15: {76: 1, 15: 0}}\n",
      "{15: {76: 'near_stressed', 15: 'same_stressed'}}\n",
      "______________\n",
      "j 16\n",
      "{16: {16: 'same_cons', 17: 'prolong'}}\n",
      "{16: 0, 17: 1}\n",
      "{16: {16: 0, 17: 1}}\n",
      "{16: {16: 'same_cons', 17: 'prolong'}}\n",
      "______________\n",
      "jː 17\n",
      "{17: {16: 'prolong', 17: 'same_cons'}}\n",
      "{16: 1, 17: 0}\n",
      "{17: {16: 1, 17: 0}}\n",
      "{17: {16: 'prolong', 17: 'same_cons'}}\n",
      "______________\n",
      "k 18\n",
      "{18: {18: 'same_cons', 19: 'palat', 20: 'palat', 21: 'prolong', 73: 'voice', 74: 'voice', 75: 'voice_prolong'}}\n",
      "{18: 0, 19: 2, 20: 2, 21: 1, 73: 1, 74: 1, 75: 1}\n",
      "{18: {18: 0, 19: 2, 20: 2, 21: 1, 73: 1, 74: 1, 75: 1}}\n",
      "{18: {18: 'same_cons', 19: 'palat', 20: 'palat', 21: 'prolong', 73: 'voice', 74: 'voice', 75: 'voice_prolong'}}\n",
      "______________\n",
      "kʲ 19\n",
      "{19: {18: 'palat', 19: 'same_cons', 20: 'prolong', 21: 'prolong', 73: 'prolong', 74: 'voice', 75: 'voice'}}\n",
      "{18: 2, 19: 0, 20: 1, 21: 1, 73: 1, 74: 1, 75: 1}\n",
      "{19: {18: 2, 19: 0, 20: 1, 21: 1, 73: 1, 74: 1, 75: 1}}\n",
      "{19: {18: 'palat', 19: 'same_cons', 20: 'prolong', 21: 'prolong', 73: 'prolong', 74: 'voice', 75: 'voice'}}\n",
      "______________\n",
      "kʲː 20\n",
      "{20: {18: 'voice', 19: 'prolong', 20: 'same_cons', 21: 'palat', 73: 'palat', 74: 'voice_prolong', 75: 'voice_prolong'}}\n",
      "{18: 1, 19: 1, 20: 0, 21: 2, 73: 2, 74: 1, 75: 1}\n",
      "{20: {18: 1, 19: 1, 20: 0, 21: 2, 73: 2, 74: 1, 75: 1}}\n",
      "{20: {18: 'voice', 19: 'prolong', 20: 'same_cons', 21: 'palat', 73: 'palat', 74: 'voice_prolong', 75: 'voice_prolong'}}\n",
      "______________\n",
      "kː 21\n",
      "{21: {18: 'prolong', 19: 'prolong', 20: 'palat', 21: 'same_cons', 73: 'voice_prolong', 74: 'voice_prolong', 75: 'voice'}}\n",
      "{18: 1, 19: 1, 20: 2, 21: 0, 73: 1, 74: 1, 75: 1}\n",
      "{21: {18: 1, 19: 1, 20: 2, 21: 0, 73: 1, 74: 1, 75: 1}}\n",
      "{21: {18: 'prolong', 19: 'prolong', 20: 'palat', 21: 'same_cons', 73: 'voice_prolong', 74: 'voice_prolong', 75: 'voice'}}\n",
      "______________\n",
      "lʲ 22\n",
      "{22: {22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'}}\n",
      "{22: 0, 23: 1, 24: 2, 25: 2}\n",
      "{22: {22: 0, 23: 1, 24: 2, 25: 2}}\n",
      "{22: {22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'}}\n",
      "______________\n",
      "lʲː 23\n",
      "{23: {22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'}}\n",
      "{22: 1, 23: 0, 24: 0, 25: 2}\n",
      "{23: {22: 1, 23: 0, 24: 0, 25: 2}}\n",
      "{23: {22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'}}\n",
      "______________\n",
      "lˠ 24\n",
      "{24: {22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}}\n",
      "{22: 2, 23: 2, 24: 0, 25: 1}\n",
      "{24: {22: 2, 23: 2, 24: 0, 25: 1}}\n",
      "{24: {22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}}\n",
      "______________\n",
      "lˠː 25\n",
      "{25: {22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'}}\n",
      "{22: 1, 23: 2, 24: 1, 25: 0}\n",
      "{25: {22: 1, 23: 2, 24: 1, 25: 0}}\n",
      "{25: {22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'}}\n",
      "______________\n",
      "m 26\n",
      "{26: {26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'}}\n",
      "{26: 0, 27: 2, 28: 2, 29: 1}\n",
      "{26: {26: 0, 27: 2, 28: 2, 29: 1}}\n",
      "{26: {26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'}}\n",
      "______________\n",
      "mʲ 27\n",
      "{27: {26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'}}\n",
      "{26: 2, 27: 0, 28: 1, 29: 1}\n",
      "{27: {26: 2, 27: 0, 28: 1, 29: 1}}\n",
      "{27: {26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'}}\n",
      "______________\n",
      "mʲː 28\n",
      "{28: {26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'}}\n",
      "{26: 1, 27: 1, 28: 0, 29: 2}\n",
      "{28: {26: 1, 27: 1, 28: 0, 29: 2}}\n",
      "{28: {26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'}}\n",
      "______________\n",
      "mː 29\n",
      "{29: {26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'}}\n",
      "{26: 1, 27: 1, 28: 2, 29: 0}\n",
      "{29: {26: 1, 27: 1, 28: 2, 29: 0}}\n",
      "{29: {26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'}}\n",
      "______________\n",
      "n 30\n",
      "{30: {30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'}}\n",
      "{30: 0, 31: 2, 32: 2, 33: 1}\n",
      "{30: {30: 0, 31: 2, 32: 2, 33: 1}}\n",
      "{30: {30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'}}\n",
      "______________\n",
      "nʲ 31\n",
      "{31: {30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'}}\n",
      "{30: 2, 31: 0, 32: 1, 33: 1}\n",
      "{31: {30: 2, 31: 0, 32: 1, 33: 1}}\n",
      "{31: {30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'}}\n",
      "______________\n",
      "nʲː 32\n",
      "{32: {30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'}}\n",
      "{30: 1, 31: 1, 32: 0, 33: 2}\n",
      "{32: {30: 1, 31: 1, 32: 0, 33: 2}}\n",
      "{32: {30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'}}\n",
      "______________\n",
      "nː 33\n",
      "{33: {30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'}}\n",
      "{30: 1, 31: 1, 32: 2, 33: 0}\n",
      "{33: {30: 1, 31: 1, 32: 2, 33: 0}}\n",
      "{33: {30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'}}\n",
      "______________\n",
      "o 34\n",
      "{34: {78: 'near_stressed', 34: 'same_stressed'}}\n",
      "{78: 1, 34: 0}\n",
      "{34: {78: 1, 34: 0}}\n",
      "{34: {78: 'near_stressed', 34: 'same_stressed'}}\n",
      "______________\n",
      "p 35\n",
      "{35: {2: 'voice', 3: 'voice', 4: 'voice', 5: 'voice_prolong', 35: 'same_cons', 36: 'palat', 37: 'palat', 38: 'prolong'}}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 0, 36: 2, 37: 2, 38: 1}\n",
      "{35: {2: 1, 3: 1, 4: 1, 5: 1, 35: 0, 36: 2, 37: 2, 38: 1}}\n",
      "{35: {2: 'voice', 3: 'voice', 4: 'voice', 5: 'voice_prolong', 35: 'same_cons', 36: 'palat', 37: 'palat', 38: 'prolong'}}\n",
      "______________\n",
      "pʲ 36\n",
      "{36: {2: 'prolong', 3: 'voice', 4: 'voice_prolong', 5: 'voice_prolong', 35: 'palat', 36: 'same_cons', 37: 'prolong', 38: 'prolong'}}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 2, 36: 0, 37: 1, 38: 1}\n",
      "{36: {2: 1, 3: 1, 4: 1, 5: 1, 35: 2, 36: 0, 37: 1, 38: 1}}\n",
      "{36: {2: 'prolong', 3: 'voice', 4: 'voice_prolong', 5: 'voice_prolong', 35: 'palat', 36: 'same_cons', 37: 'prolong', 38: 'prolong'}}\n",
      "______________\n",
      "pʲː 37\n",
      "{37: {2: 'prolong', 3: 'voice_prolong', 4: 'voice', 5: 'voice', 35: 'voice', 36: 'prolong', 37: 'same_cons', 38: 'palat'}}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 0, 38: 2}\n",
      "{37: {2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 0, 38: 2}}\n",
      "{37: {2: 'prolong', 3: 'voice_prolong', 4: 'voice', 5: 'voice', 35: 'voice', 36: 'prolong', 37: 'same_cons', 38: 'palat'}}\n",
      "______________\n",
      "pː 38\n",
      "{38: {2: 'voice_prolong', 3: 'voice_prolong', 4: 'voice_prolong', 5: 'voice', 35: 'prolong', 36: 'prolong', 37: 'palat', 38: 'same_cons'}}\n",
      "{2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 2, 38: 0}\n",
      "{38: {2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 2, 38: 0}}\n",
      "{38: {2: 'voice_prolong', 3: 'voice_prolong', 4: 'voice_prolong', 5: 'voice', 35: 'prolong', 36: 'prolong', 37: 'palat', 38: 'same_cons'}}\n",
      "______________\n",
      "r 39\n",
      "{39: {39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'}}\n",
      "{39: 0, 40: 2, 41: 2, 42: 1}\n",
      "{39: {39: 0, 40: 2, 41: 2, 42: 1}}\n",
      "{39: {39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'}}\n",
      "______________\n",
      "rʲ 40\n",
      "{40: {39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'}}\n",
      "{39: 2, 40: 0, 41: 1, 42: 1}\n",
      "{40: {39: 2, 40: 0, 41: 1, 42: 1}}\n",
      "{40: {39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'}}\n",
      "______________\n",
      "rʲː 41\n",
      "{41: {39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'}}\n",
      "{39: 1, 40: 1, 41: 0, 42: 2}\n",
      "{41: {39: 1, 40: 1, 41: 0, 42: 2}}\n",
      "{41: {39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'}}\n",
      "______________\n",
      "rː 42\n",
      "{42: {39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'}}\n",
      "{39: 1, 40: 1, 41: 2, 42: 0}\n",
      "{42: {39: 1, 40: 1, 41: 2, 42: 0}}\n",
      "{42: {39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'}}\n",
      "______________\n",
      "s 43\n",
      "{43: {43: 'same_cons', 44: 'palat', 45: 'palat', 46: 'prolong', 63: 'voice', 64: 'voice', 65: 'voice', 66: 'voice_prolong'}}\n",
      "{43: 0, 44: 2, 45: 2, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{43: {43: 0, 44: 2, 45: 2, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}}\n",
      "{43: {43: 'same_cons', 44: 'palat', 45: 'palat', 46: 'prolong', 63: 'voice', 64: 'voice', 65: 'voice', 66: 'voice_prolong'}}\n",
      "______________\n",
      "sʲ 44\n",
      "{44: {43: 'palat', 44: 'same_cons', 45: 'prolong', 46: 'prolong', 63: 'prolong', 64: 'voice', 65: 'voice_prolong', 66: 'voice_prolong'}}\n",
      "{43: 2, 44: 0, 45: 1, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{44: {43: 2, 44: 0, 45: 1, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1}}\n",
      "{44: {43: 'palat', 44: 'same_cons', 45: 'prolong', 46: 'prolong', 63: 'prolong', 64: 'voice', 65: 'voice_prolong', 66: 'voice_prolong'}}\n",
      "______________\n",
      "sʲː 45\n",
      "{45: {43: 'voice_prolong', 44: 'prolong', 45: 'same_cons', 46: 'palat', 63: 'palat', 64: 'voice_prolong', 65: 'voice', 66: 'voice'}}\n",
      "{43: 1, 44: 1, 45: 0, 46: 2, 63: 2, 64: 1, 65: 1, 66: 1}\n",
      "{45: {43: 1, 44: 1, 45: 0, 46: 2, 63: 2, 64: 1, 65: 1, 66: 1}}\n",
      "{45: {43: 'voice_prolong', 44: 'prolong', 45: 'same_cons', 46: 'palat', 63: 'palat', 64: 'voice_prolong', 65: 'voice', 66: 'voice'}}\n",
      "______________\n",
      "sː 46\n",
      "{46: {43: 'prolong', 44: 'prolong', 45: 'palat', 46: 'same_cons', 63: 'voice_prolong', 64: 'voice_prolong', 65: 'voice_prolong', 66: 'voice'}}\n",
      "{43: 1, 44: 1, 45: 2, 46: 0, 63: 1, 64: 1, 65: 1, 66: 1}\n",
      "{46: {43: 1, 44: 1, 45: 2, 46: 0, 63: 1, 64: 1, 65: 1, 66: 1}}\n",
      "{46: {43: 'prolong', 44: 'prolong', 45: 'palat', 46: 'same_cons', 63: 'voice_prolong', 64: 'voice_prolong', 65: 'voice_prolong', 66: 'voice'}}\n",
      "______________\n",
      "t 47\n",
      "{47: {6: 'voice', 7: 'voice', 8: 'voice', 9: 'voice_prolong', 47: 'same_cons', 48: 'palat', 49: 'palat', 50: 'prolong'}}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 0, 48: 2, 49: 2, 50: 1}\n",
      "{47: {6: 1, 7: 1, 8: 1, 9: 1, 47: 0, 48: 2, 49: 2, 50: 1}}\n",
      "{47: {6: 'voice', 7: 'voice', 8: 'voice', 9: 'voice_prolong', 47: 'same_cons', 48: 'palat', 49: 'palat', 50: 'prolong'}}\n",
      "______________\n",
      "tʲ 48\n",
      "{48: {6: 'prolong', 7: 'voice', 8: 'voice_prolong', 9: 'voice_prolong', 47: 'palat', 48: 'same_cons', 49: 'prolong', 50: 'prolong'}}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 2, 48: 0, 49: 1, 50: 1}\n",
      "{48: {6: 1, 7: 1, 8: 1, 9: 1, 47: 2, 48: 0, 49: 1, 50: 1}}\n",
      "{48: {6: 'prolong', 7: 'voice', 8: 'voice_prolong', 9: 'voice_prolong', 47: 'palat', 48: 'same_cons', 49: 'prolong', 50: 'prolong'}}\n",
      "______________\n",
      "tʲː 49\n",
      "{49: {6: 'prolong', 7: 'voice_prolong', 8: 'voice', 9: 'voice', 47: 'voice', 48: 'prolong', 49: 'same_cons', 50: 'palat'}}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 0, 50: 2}\n",
      "{49: {6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 0, 50: 2}}\n",
      "{49: {6: 'prolong', 7: 'voice_prolong', 8: 'voice', 9: 'voice', 47: 'voice', 48: 'prolong', 49: 'same_cons', 50: 'palat'}}\n",
      "______________\n",
      "tː 50\n",
      "{50: {6: 'voice_prolong', 7: 'voice_prolong', 8: 'voice_prolong', 9: 'voice', 47: 'prolong', 48: 'prolong', 49: 'palat', 50: 'same_cons'}}\n",
      "{6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 2, 50: 0}\n",
      "{50: {6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 2, 50: 0}}\n",
      "{50: {6: 'voice_prolong', 7: 'voice_prolong', 8: 'voice_prolong', 9: 'voice', 47: 'prolong', 48: 'prolong', 49: 'palat', 50: 'same_cons'}}\n",
      "______________\n",
      "t͡s 51\n",
      "{51: {10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'}}\n",
      "{10: 1, 11: 1, 51: 0, 52: 2, 53: 1}\n",
      "{51: {10: 1, 11: 1, 51: 0, 52: 2, 53: 1}}\n",
      "{51: {10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'}}\n",
      "______________\n",
      "t͡sʲ 52\n",
      "{52: {10: 'prolong', 11: 'voice', 51: 'palat', 52: 'same_cons', 53: 'same_cons'}}\n",
      "{10: 1, 11: 1, 51: 2, 52: 0, 53: 0}\n",
      "{52: {10: 1, 11: 1, 51: 2, 52: 0, 53: 0}}\n",
      "{52: {10: 'prolong', 11: 'voice', 51: 'palat', 52: 'same_cons', 53: 'same_cons'}}\n",
      "______________\n",
      "t͡sː 53\n",
      "{53: {10: 'voice_prolong', 11: 'voice_prolong', 51: 'prolong', 52: 'prolong', 53: 'same_cons'}}\n",
      "{10: 1, 11: 1, 51: 1, 52: 1, 53: 0}\n",
      "{53: {10: 1, 11: 1, 51: 1, 52: 1, 53: 0}}\n",
      "{53: {10: 'voice_prolong', 11: 'voice_prolong', 51: 'prolong', 52: 'prolong', 53: 'same_cons'}}\n",
      "______________\n",
      "t͡ɕ 54\n",
      "{54: {54: 'same_cons', 55: 'prolong'}}\n",
      "{54: 0, 55: 1}\n",
      "{54: {54: 0, 55: 1}}\n",
      "{54: {54: 'same_cons', 55: 'prolong'}}\n",
      "______________\n",
      "t͡ɕː 55\n",
      "{55: {54: 'prolong', 55: 'same_cons'}}\n",
      "{54: 1, 55: 0}\n",
      "{55: {54: 1, 55: 0}}\n",
      "{55: {54: 'prolong', 55: 'same_cons'}}\n",
      "______________\n",
      "u 56\n",
      "{56: {82: 'near_stressed', 56: 'same_stressed'}}\n",
      "{82: 1, 56: 0}\n",
      "{56: {82: 1, 56: 0}}\n",
      "{56: {82: 'near_stressed', 56: 'same_stressed'}}\n",
      "______________\n",
      "v 57\n",
      "{57: {13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}}\n",
      "{13: 1, 14: 1, 57: 0, 58: 2, 59: 2, 60: 1}\n",
      "{57: {13: 1, 14: 1, 57: 0, 58: 2, 59: 2, 60: 1}}\n",
      "{57: {13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}}\n",
      "______________\n",
      "vʲ 58\n",
      "{58: {13: 'prolong', 14: 'voice', 57: 'palat', 58: 'same_cons', 59: 'prolong', 60: 'prolong'}}\n",
      "{13: 1, 14: 1, 57: 2, 58: 0, 59: 1, 60: 1}\n",
      "{58: {13: 1, 14: 1, 57: 2, 58: 0, 59: 1, 60: 1}}\n",
      "{58: {13: 'prolong', 14: 'voice', 57: 'palat', 58: 'same_cons', 59: 'prolong', 60: 'prolong'}}\n",
      "______________\n",
      "vʲː 59\n",
      "{59: {13: 'prolong', 14: 'voice_prolong', 57: 'voice_prolong', 58: 'prolong', 59: 'same_cons', 60: 'palat'}}\n",
      "{13: 1, 14: 1, 57: 1, 58: 1, 59: 0, 60: 2}\n",
      "{59: {13: 1, 14: 1, 57: 1, 58: 1, 59: 0, 60: 2}}\n",
      "{59: {13: 'prolong', 14: 'voice_prolong', 57: 'voice_prolong', 58: 'prolong', 59: 'same_cons', 60: 'palat'}}\n",
      "______________\n",
      "vː 60\n",
      "{60: {13: 'voice_prolong', 14: 'voice_prolong', 57: 'prolong', 58: 'prolong', 59: 'palat', 60: 'same_cons'}}\n",
      "{13: 1, 14: 1, 57: 1, 58: 1, 59: 2, 60: 0}\n",
      "{60: {13: 1, 14: 1, 57: 1, 58: 1, 59: 2, 60: 0}}\n",
      "{60: {13: 'voice_prolong', 14: 'voice_prolong', 57: 'prolong', 58: 'prolong', 59: 'palat', 60: 'same_cons'}}\n",
      "______________\n",
      "x 61\n",
      "{61: {61: 'same_cons', 62: 'palat'}}\n",
      "{61: 0, 62: 2}\n",
      "{61: {61: 0, 62: 2}}\n",
      "{61: {61: 'same_cons', 62: 'palat'}}\n",
      "______________\n",
      "xʲ 62\n",
      "{62: {61: 'palat', 62: 'same_cons'}}\n",
      "{61: 2, 62: 0}\n",
      "{62: {61: 2, 62: 0}}\n",
      "{62: {61: 'palat', 62: 'same_cons'}}\n",
      "______________\n",
      "z 63\n",
      "{63: {43: 'voice', 44: 'voice', 45: 'voice', 46: 'voice_prolong', 63: 'same_cons', 64: 'palat', 65: 'palat', 66: 'prolong'}}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 0, 64: 2, 65: 2, 66: 1}\n",
      "{63: {43: 1, 44: 1, 45: 1, 46: 1, 63: 0, 64: 2, 65: 2, 66: 1}}\n",
      "{63: {43: 'voice', 44: 'voice', 45: 'voice', 46: 'voice_prolong', 63: 'same_cons', 64: 'palat', 65: 'palat', 66: 'prolong'}}\n",
      "______________\n",
      "zʲ 64\n",
      "{64: {43: 'prolong', 44: 'voice', 45: 'voice_prolong', 46: 'voice_prolong', 63: 'palat', 64: 'same_cons', 65: 'prolong', 66: 'prolong'}}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 2, 64: 0, 65: 1, 66: 1}\n",
      "{64: {43: 1, 44: 1, 45: 1, 46: 1, 63: 2, 64: 0, 65: 1, 66: 1}}\n",
      "{64: {43: 'prolong', 44: 'voice', 45: 'voice_prolong', 46: 'voice_prolong', 63: 'palat', 64: 'same_cons', 65: 'prolong', 66: 'prolong'}}\n",
      "______________\n",
      "zʲː 65\n",
      "{65: {43: 'prolong', 44: 'voice_prolong', 45: 'voice', 46: 'voice', 63: 'voice', 64: 'prolong', 65: 'same_cons', 66: 'palat'}}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 0, 66: 2}\n",
      "{65: {43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 0, 66: 2}}\n",
      "{65: {43: 'prolong', 44: 'voice_prolong', 45: 'voice', 46: 'voice', 63: 'voice', 64: 'prolong', 65: 'same_cons', 66: 'palat'}}\n",
      "______________\n",
      "zː 66\n",
      "{66: {43: 'voice_prolong', 44: 'voice_prolong', 45: 'voice_prolong', 46: 'voice', 63: 'prolong', 64: 'prolong', 65: 'palat', 66: 'same_cons'}}\n",
      "{43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 2, 66: 0}\n",
      "{66: {43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 2, 66: 0}}\n",
      "{66: {43: 'voice_prolong', 44: 'voice_prolong', 45: 'voice_prolong', 46: 'voice', 63: 'prolong', 64: 'prolong', 65: 'palat', 66: 'same_cons'}}\n",
      "______________\n",
      "æ 67\n",
      "{67: {1: 'near_stressed', 67: 'same_stressed'}}\n",
      "{1: 1, 67: 0}\n",
      "{67: {1: 1, 67: 0}}\n",
      "{67: {1: 'near_stressed', 67: 'same_stressed'}}\n",
      "______________\n",
      "ɐ 68\n",
      "{68: {68: 'same_v'}}\n",
      "{68: 0}\n",
      "{68: {68: 0}}\n",
      "{68: {68: 'same_v'}}\n",
      "______________\n",
      "ɕ 69\n",
      "{69: {69: 'same_cons', 70: 'prolong'}}\n",
      "{69: 0, 70: 1}\n",
      "{69: {69: 0, 70: 1}}\n",
      "{69: {69: 'same_cons', 70: 'prolong'}}\n",
      "______________\n",
      "ɕː 70\n",
      "{70: {69: 'prolong', 70: 'same_cons'}}\n",
      "{69: 1, 70: 0}\n",
      "{70: {69: 1, 70: 0}}\n",
      "{70: {69: 'prolong', 70: 'same_cons'}}\n",
      "______________\n",
      "ə 71\n",
      "{71: {71: 'same_v'}}\n",
      "{71: 0}\n",
      "{71: {71: 0}}\n",
      "{71: {71: 'same_v'}}\n",
      "______________\n",
      "ɛ 72\n",
      "{72: {12: 'near_stressed', 72: 'same_stressed'}}\n",
      "{12: 1, 72: 0}\n",
      "{72: {12: 1, 72: 0}}\n",
      "{72: {12: 'near_stressed', 72: 'same_stressed'}}\n",
      "______________\n",
      "ɡ 73\n",
      "{73: {18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 0, 74: 2, 75: 1}\n",
      "{73: {18: 1, 19: 1, 20: 1, 21: 1, 73: 0, 74: 2, 75: 1}}\n",
      "{73: {18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}}\n",
      "______________\n",
      "ɡʲ 74\n",
      "{74: {18: 'prolong', 19: 'voice', 20: 'voice_prolong', 21: 'voice_prolong', 73: 'palat', 74: 'same_cons', 75: 'same_cons'}}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 2, 74: 0, 75: 0}\n",
      "{74: {18: 1, 19: 1, 20: 1, 21: 1, 73: 2, 74: 0, 75: 0}}\n",
      "{74: {18: 'prolong', 19: 'voice', 20: 'voice_prolong', 21: 'voice_prolong', 73: 'palat', 74: 'same_cons', 75: 'same_cons'}}\n",
      "______________\n",
      "ɡː 75\n",
      "{75: {18: 'voice_prolong', 19: 'voice_prolong', 20: 'voice_prolong', 21: 'voice', 73: 'prolong', 74: 'prolong', 75: 'same_cons'}}\n",
      "{18: 1, 19: 1, 20: 1, 21: 1, 73: 1, 74: 1, 75: 0}\n",
      "{75: {18: 1, 19: 1, 20: 1, 21: 1, 73: 1, 74: 1, 75: 0}}\n",
      "{75: {18: 'voice_prolong', 19: 'voice_prolong', 20: 'voice_prolong', 21: 'voice', 73: 'prolong', 74: 'prolong', 75: 'same_cons'}}\n",
      "______________\n",
      "ɨ 76\n",
      "{76: {15: 'near_stressed', 76: 'same_stressed'}}\n",
      "{15: 1, 76: 0}\n",
      "{76: {15: 1, 76: 0}}\n",
      "{76: {15: 'near_stressed', 76: 'same_stressed'}}\n",
      "______________\n",
      "ɪ 77\n",
      "{77: {77: 'same_v'}}\n",
      "{77: 0}\n",
      "{77: {77: 0}}\n",
      "{77: {77: 'same_v'}}\n",
      "______________\n",
      "ɵ 78\n",
      "{78: {34: 'near_stressed', 78: 'same_stressed'}}\n",
      "{34: 1, 78: 0}\n",
      "{78: {34: 1, 78: 0}}\n",
      "{78: {34: 'near_stressed', 78: 'same_stressed'}}\n",
      "______________\n",
      "ʂ 79\n",
      "{79: {79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'}}\n",
      "{79: 0, 80: 1, 84: 1, 85: 1}\n",
      "{79: {79: 0, 80: 1, 84: 1, 85: 1}}\n",
      "{79: {79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'}}\n",
      "______________\n",
      "ʂː 80\n",
      "{80: {79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'}}\n",
      "{79: 1, 80: 0, 84: 1, 85: 1}\n",
      "{80: {79: 1, 80: 0, 84: 1, 85: 1}}\n",
      "{80: {79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'}}\n",
      "______________\n",
      "ʈ͡ʂ 81\n",
      "{81: {81: 'same_cons'}}\n",
      "{81: 0}\n",
      "{81: {81: 0}}\n",
      "{81: {81: 'same_cons'}}\n",
      "______________\n",
      "ʉ 82\n",
      "{82: {56: 'near_stressed', 82: 'same_stressed'}}\n",
      "{56: 1, 82: 0}\n",
      "{82: {56: 1, 82: 0}}\n",
      "{82: {56: 'near_stressed', 82: 'same_stressed'}}\n",
      "______________\n",
      "ʊ 83\n",
      "{83: {83: 'same_v'}}\n",
      "{83: 0}\n",
      "{83: {83: 0}}\n",
      "{83: {83: 'same_v'}}\n",
      "______________\n",
      "ʐ 84\n",
      "{84: {79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'}}\n",
      "{79: 1, 80: 1, 84: 0, 85: 1}\n",
      "{84: {79: 1, 80: 1, 84: 0, 85: 1}}\n",
      "{84: {79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'}}\n",
      "______________\n",
      "ʐː 85\n",
      "{85: {79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}}\n",
      "{79: 1, 80: 1, 84: 1, 85: 0}\n",
      "{85: {79: 1, 80: 1, 84: 1, 85: 0}}\n",
      "{85: {79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}}\n",
      "______________\n"
     ]
    }
   ],
   "source": [
    "for instance in instances_ipasimilarities:\n",
    "    print(instance.sign, instance.number)\n",
    "    print(instance.int_dict_int_pattern)\n",
    "    print(instance.similarities_int_score)\n",
    "    print(instance.int_dict_int_score)\n",
    "    print(instance.int_dict_int_pattern)\n",
    "    print(\"______________\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create_dict_int_dict_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def create_dict_int_dict_int_score(instances_ipasimilarities) -> dict[int, dict[int, int]]:\n",
    "    dict_int_dict_int_score = {}\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.int_dict_int_score:\n",
    "            dict_int_dict_int_score.update(_instance.int_dict_int_score)\n",
    "    return dict_int_dict_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "dict_int_dict_int_score = create_dict_int_dict_int_score(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: {67: 1, 1: 0},\n 2: {2: 0, 3: 2, 4: 2, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1},\n 3: {2: 2, 3: 0, 4: 1, 5: 1, 35: 1, 36: 1, 37: 1, 38: 1},\n 4: {2: 1, 3: 1, 4: 0, 5: 2, 35: 2, 36: 1, 37: 1, 38: 1},\n 5: {2: 1, 3: 1, 4: 2, 5: 0, 35: 1, 36: 1, 37: 1, 38: 1},\n 6: {6: 0, 7: 2, 8: 2, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1},\n 7: {6: 2, 7: 0, 8: 1, 9: 1, 47: 1, 48: 1, 49: 1, 50: 1},\n 8: {6: 1, 7: 1, 8: 0, 9: 2, 47: 2, 48: 1, 49: 1, 50: 1},\n 9: {6: 1, 7: 1, 8: 2, 9: 0, 47: 1, 48: 1, 49: 1, 50: 1},\n 10: {10: 0, 11: 2, 51: 1, 52: 1, 53: 1},\n 11: {10: 2, 11: 0, 51: 0, 52: 1, 53: 1},\n 12: {72: 1, 12: 0},\n 13: {13: 0, 14: 2, 57: 1, 58: 1, 59: 1, 60: 1},\n 14: {13: 2, 14: 0, 57: 0, 58: 1, 59: 1, 60: 1},\n 15: {76: 1, 15: 0},\n 16: {16: 0, 17: 1},\n 17: {16: 1, 17: 0},\n 18: {18: 0, 19: 2, 20: 2, 21: 1, 73: 1, 74: 1, 75: 1},\n 19: {18: 2, 19: 0, 20: 1, 21: 1, 73: 1, 74: 1, 75: 1},\n 20: {18: 1, 19: 1, 20: 0, 21: 2, 73: 2, 74: 1, 75: 1},\n 21: {18: 1, 19: 1, 20: 2, 21: 0, 73: 1, 74: 1, 75: 1},\n 22: {22: 0, 23: 1, 24: 2, 25: 2},\n 23: {22: 1, 23: 0, 24: 0, 25: 2},\n 24: {22: 2, 23: 2, 24: 0, 25: 1},\n 25: {22: 1, 23: 2, 24: 1, 25: 0},\n 26: {26: 0, 27: 2, 28: 2, 29: 1},\n 27: {26: 2, 27: 0, 28: 1, 29: 1},\n 28: {26: 1, 27: 1, 28: 0, 29: 2},\n 29: {26: 1, 27: 1, 28: 2, 29: 0},\n 30: {30: 0, 31: 2, 32: 2, 33: 1},\n 31: {30: 2, 31: 0, 32: 1, 33: 1},\n 32: {30: 1, 31: 1, 32: 0, 33: 2},\n 33: {30: 1, 31: 1, 32: 2, 33: 0},\n 34: {78: 1, 34: 0},\n 35: {2: 1, 3: 1, 4: 1, 5: 1, 35: 0, 36: 2, 37: 2, 38: 1},\n 36: {2: 1, 3: 1, 4: 1, 5: 1, 35: 2, 36: 0, 37: 1, 38: 1},\n 37: {2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 0, 38: 2},\n 38: {2: 1, 3: 1, 4: 1, 5: 1, 35: 1, 36: 1, 37: 2, 38: 0},\n 39: {39: 0, 40: 2, 41: 2, 42: 1},\n 40: {39: 2, 40: 0, 41: 1, 42: 1},\n 41: {39: 1, 40: 1, 41: 0, 42: 2},\n 42: {39: 1, 40: 1, 41: 2, 42: 0},\n 43: {43: 0, 44: 2, 45: 2, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1},\n 44: {43: 2, 44: 0, 45: 1, 46: 1, 63: 1, 64: 1, 65: 1, 66: 1},\n 45: {43: 1, 44: 1, 45: 0, 46: 2, 63: 2, 64: 1, 65: 1, 66: 1},\n 46: {43: 1, 44: 1, 45: 2, 46: 0, 63: 1, 64: 1, 65: 1, 66: 1},\n 47: {6: 1, 7: 1, 8: 1, 9: 1, 47: 0, 48: 2, 49: 2, 50: 1},\n 48: {6: 1, 7: 1, 8: 1, 9: 1, 47: 2, 48: 0, 49: 1, 50: 1},\n 49: {6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 0, 50: 2},\n 50: {6: 1, 7: 1, 8: 1, 9: 1, 47: 1, 48: 1, 49: 2, 50: 0},\n 51: {10: 1, 11: 1, 51: 0, 52: 2, 53: 1},\n 52: {10: 1, 11: 1, 51: 2, 52: 0, 53: 0},\n 53: {10: 1, 11: 1, 51: 1, 52: 1, 53: 0},\n 54: {54: 0, 55: 1},\n 55: {54: 1, 55: 0},\n 56: {82: 1, 56: 0},\n 57: {13: 1, 14: 1, 57: 0, 58: 2, 59: 2, 60: 1},\n 58: {13: 1, 14: 1, 57: 2, 58: 0, 59: 1, 60: 1},\n 59: {13: 1, 14: 1, 57: 1, 58: 1, 59: 0, 60: 2},\n 60: {13: 1, 14: 1, 57: 1, 58: 1, 59: 2, 60: 0},\n 61: {61: 0, 62: 2},\n 62: {61: 2, 62: 0},\n 63: {43: 1, 44: 1, 45: 1, 46: 1, 63: 0, 64: 2, 65: 2, 66: 1},\n 64: {43: 1, 44: 1, 45: 1, 46: 1, 63: 2, 64: 0, 65: 1, 66: 1},\n 65: {43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 0, 66: 2},\n 66: {43: 1, 44: 1, 45: 1, 46: 1, 63: 1, 64: 1, 65: 2, 66: 0},\n 67: {1: 1, 67: 0},\n 68: {68: 0},\n 69: {69: 0, 70: 1},\n 70: {69: 1, 70: 0},\n 71: {71: 0},\n 72: {12: 1, 72: 0},\n 73: {18: 1, 19: 1, 20: 1, 21: 1, 73: 0, 74: 2, 75: 1},\n 74: {18: 1, 19: 1, 20: 1, 21: 1, 73: 2, 74: 0, 75: 0},\n 75: {18: 1, 19: 1, 20: 1, 21: 1, 73: 1, 74: 1, 75: 0},\n 76: {15: 1, 76: 0},\n 77: {77: 0},\n 78: {34: 1, 78: 0},\n 79: {79: 0, 80: 1, 84: 1, 85: 1},\n 80: {79: 1, 80: 0, 84: 1, 85: 1},\n 81: {81: 0},\n 82: {56: 1, 82: 0},\n 83: {83: 0},\n 84: {79: 1, 80: 1, 84: 0, 85: 1},\n 85: {79: 1, 80: 1, 84: 1, 85: 0}}"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_int_dict_int_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create_dict_int_dict_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def create_dict_int_dict_int_pattern(instances_ipasimilarities) -> dict[int, dict[int, str]]:\n",
    "    dict_int_dict_int_pattern = {}\n",
    "    for _instance in instances_ipasimilarities:\n",
    "        if _instance.int_dict_int_pattern:\n",
    "            dict_int_dict_int_pattern.update(_instance.int_dict_int_pattern)\n",
    "    return dict_int_dict_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "dict_int_dict_int_pattern = create_dict_int_dict_int_pattern(instances_ipasimilarities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: {67: 'near_stressed', 1: 'same_stressed'},\n 2: {2: 'same_cons',\n  3: 'palat',\n  4: 'palat',\n  5: 'prolong',\n  35: 'voice',\n  36: 'voice',\n  37: 'voice',\n  38: 'voice_prolong'},\n 3: {2: 'palat',\n  3: 'same_cons',\n  4: 'prolong',\n  5: 'prolong',\n  35: 'prolong',\n  36: 'voice',\n  37: 'voice_prolong',\n  38: 'voice_prolong'},\n 4: {2: 'voice_prolong',\n  3: 'prolong',\n  4: 'same_cons',\n  5: 'palat',\n  35: 'palat',\n  36: 'voice_prolong',\n  37: 'voice',\n  38: 'voice'},\n 5: {2: 'prolong',\n  3: 'prolong',\n  4: 'palat',\n  5: 'same_cons',\n  35: 'voice_prolong',\n  36: 'voice_prolong',\n  37: 'voice_prolong',\n  38: 'voice'},\n 6: {6: 'same_cons',\n  7: 'palat',\n  8: 'palat',\n  9: 'prolong',\n  47: 'voice',\n  48: 'voice',\n  49: 'voice',\n  50: 'voice_prolong'},\n 7: {6: 'palat',\n  7: 'same_cons',\n  8: 'prolong',\n  9: 'prolong',\n  47: 'prolong',\n  48: 'voice',\n  49: 'voice_prolong',\n  50: 'voice_prolong'},\n 8: {6: 'voice_prolong',\n  7: 'prolong',\n  8: 'same_cons',\n  9: 'palat',\n  47: 'palat',\n  48: 'voice_prolong',\n  49: 'voice',\n  50: 'voice'},\n 9: {6: 'prolong',\n  7: 'prolong',\n  8: 'palat',\n  9: 'same_cons',\n  47: 'voice_prolong',\n  48: 'voice_prolong',\n  49: 'voice_prolong',\n  50: 'voice'},\n 10: {10: 'same_cons',\n  11: 'palat',\n  51: 'voice',\n  52: 'voice',\n  53: 'voice_prolong'},\n 11: {10: 'palat', 11: 'same_cons', 51: 'same_cons', 52: 'voice', 53: 'voice'},\n 12: {72: 'near_stressed', 12: 'same_stressed'},\n 13: {13: 'same_cons',\n  14: 'palat',\n  57: 'voice',\n  58: 'voice',\n  59: 'voice',\n  60: 'voice_prolong'},\n 14: {13: 'palat',\n  14: 'same_cons',\n  57: 'same_cons',\n  58: 'voice',\n  59: 'voice_prolong',\n  60: 'voice_prolong'},\n 15: {76: 'near_stressed', 15: 'same_stressed'},\n 16: {16: 'same_cons', 17: 'prolong'},\n 17: {16: 'prolong', 17: 'same_cons'},\n 18: {18: 'same_cons',\n  19: 'palat',\n  20: 'palat',\n  21: 'prolong',\n  73: 'voice',\n  74: 'voice',\n  75: 'voice_prolong'},\n 19: {18: 'palat',\n  19: 'same_cons',\n  20: 'prolong',\n  21: 'prolong',\n  73: 'prolong',\n  74: 'voice',\n  75: 'voice'},\n 20: {18: 'voice',\n  19: 'prolong',\n  20: 'same_cons',\n  21: 'palat',\n  73: 'palat',\n  74: 'voice_prolong',\n  75: 'voice_prolong'},\n 21: {18: 'prolong',\n  19: 'prolong',\n  20: 'palat',\n  21: 'same_cons',\n  73: 'voice_prolong',\n  74: 'voice_prolong',\n  75: 'voice'},\n 22: {22: 'same_cons', 23: 'prolong', 24: 'palat', 25: 'palat'},\n 23: {22: 'prolong', 23: 'same_cons', 24: 'same_cons', 25: 'palat'},\n 24: {22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'},\n 25: {22: 'prolong', 23: 'palat', 24: 'prolong', 25: 'same_cons'},\n 26: {26: 'same_cons', 27: 'palat', 28: 'palat', 29: 'prolong'},\n 27: {26: 'palat', 27: 'same_cons', 28: 'prolong', 29: 'prolong'},\n 28: {26: 'prolong', 27: 'prolong', 28: 'same_cons', 29: 'palat'},\n 29: {26: 'prolong', 27: 'prolong', 28: 'palat', 29: 'same_cons'},\n 30: {30: 'same_cons', 31: 'palat', 32: 'palat', 33: 'prolong'},\n 31: {30: 'palat', 31: 'same_cons', 32: 'prolong', 33: 'prolong'},\n 32: {30: 'prolong', 31: 'prolong', 32: 'same_cons', 33: 'palat'},\n 33: {30: 'prolong', 31: 'prolong', 32: 'palat', 33: 'same_cons'},\n 34: {78: 'near_stressed', 34: 'same_stressed'},\n 35: {2: 'voice',\n  3: 'voice',\n  4: 'voice',\n  5: 'voice_prolong',\n  35: 'same_cons',\n  36: 'palat',\n  37: 'palat',\n  38: 'prolong'},\n 36: {2: 'prolong',\n  3: 'voice',\n  4: 'voice_prolong',\n  5: 'voice_prolong',\n  35: 'palat',\n  36: 'same_cons',\n  37: 'prolong',\n  38: 'prolong'},\n 37: {2: 'prolong',\n  3: 'voice_prolong',\n  4: 'voice',\n  5: 'voice',\n  35: 'voice',\n  36: 'prolong',\n  37: 'same_cons',\n  38: 'palat'},\n 38: {2: 'voice_prolong',\n  3: 'voice_prolong',\n  4: 'voice_prolong',\n  5: 'voice',\n  35: 'prolong',\n  36: 'prolong',\n  37: 'palat',\n  38: 'same_cons'},\n 39: {39: 'same_cons', 40: 'palat', 41: 'palat', 42: 'prolong'},\n 40: {39: 'palat', 40: 'same_cons', 41: 'prolong', 42: 'prolong'},\n 41: {39: 'prolong', 40: 'prolong', 41: 'same_cons', 42: 'palat'},\n 42: {39: 'prolong', 40: 'prolong', 41: 'palat', 42: 'same_cons'},\n 43: {43: 'same_cons',\n  44: 'palat',\n  45: 'palat',\n  46: 'prolong',\n  63: 'voice',\n  64: 'voice',\n  65: 'voice',\n  66: 'voice_prolong'},\n 44: {43: 'palat',\n  44: 'same_cons',\n  45: 'prolong',\n  46: 'prolong',\n  63: 'prolong',\n  64: 'voice',\n  65: 'voice_prolong',\n  66: 'voice_prolong'},\n 45: {43: 'voice_prolong',\n  44: 'prolong',\n  45: 'same_cons',\n  46: 'palat',\n  63: 'palat',\n  64: 'voice_prolong',\n  65: 'voice',\n  66: 'voice'},\n 46: {43: 'prolong',\n  44: 'prolong',\n  45: 'palat',\n  46: 'same_cons',\n  63: 'voice_prolong',\n  64: 'voice_prolong',\n  65: 'voice_prolong',\n  66: 'voice'},\n 47: {6: 'voice',\n  7: 'voice',\n  8: 'voice',\n  9: 'voice_prolong',\n  47: 'same_cons',\n  48: 'palat',\n  49: 'palat',\n  50: 'prolong'},\n 48: {6: 'prolong',\n  7: 'voice',\n  8: 'voice_prolong',\n  9: 'voice_prolong',\n  47: 'palat',\n  48: 'same_cons',\n  49: 'prolong',\n  50: 'prolong'},\n 49: {6: 'prolong',\n  7: 'voice_prolong',\n  8: 'voice',\n  9: 'voice',\n  47: 'voice',\n  48: 'prolong',\n  49: 'same_cons',\n  50: 'palat'},\n 50: {6: 'voice_prolong',\n  7: 'voice_prolong',\n  8: 'voice_prolong',\n  9: 'voice',\n  47: 'prolong',\n  48: 'prolong',\n  49: 'palat',\n  50: 'same_cons'},\n 51: {10: 'voice', 11: 'voice', 51: 'same_cons', 52: 'palat', 53: 'prolong'},\n 52: {10: 'prolong',\n  11: 'voice',\n  51: 'palat',\n  52: 'same_cons',\n  53: 'same_cons'},\n 53: {10: 'voice_prolong',\n  11: 'voice_prolong',\n  51: 'prolong',\n  52: 'prolong',\n  53: 'same_cons'},\n 54: {54: 'same_cons', 55: 'prolong'},\n 55: {54: 'prolong', 55: 'same_cons'},\n 56: {82: 'near_stressed', 56: 'same_stressed'},\n 57: {13: 'voice',\n  14: 'voice',\n  57: 'same_cons',\n  58: 'palat',\n  59: 'palat',\n  60: 'prolong'},\n 58: {13: 'prolong',\n  14: 'voice',\n  57: 'palat',\n  58: 'same_cons',\n  59: 'prolong',\n  60: 'prolong'},\n 59: {13: 'prolong',\n  14: 'voice_prolong',\n  57: 'voice_prolong',\n  58: 'prolong',\n  59: 'same_cons',\n  60: 'palat'},\n 60: {13: 'voice_prolong',\n  14: 'voice_prolong',\n  57: 'prolong',\n  58: 'prolong',\n  59: 'palat',\n  60: 'same_cons'},\n 61: {61: 'same_cons', 62: 'palat'},\n 62: {61: 'palat', 62: 'same_cons'},\n 63: {43: 'voice',\n  44: 'voice',\n  45: 'voice',\n  46: 'voice_prolong',\n  63: 'same_cons',\n  64: 'palat',\n  65: 'palat',\n  66: 'prolong'},\n 64: {43: 'prolong',\n  44: 'voice',\n  45: 'voice_prolong',\n  46: 'voice_prolong',\n  63: 'palat',\n  64: 'same_cons',\n  65: 'prolong',\n  66: 'prolong'},\n 65: {43: 'prolong',\n  44: 'voice_prolong',\n  45: 'voice',\n  46: 'voice',\n  63: 'voice',\n  64: 'prolong',\n  65: 'same_cons',\n  66: 'palat'},\n 66: {43: 'voice_prolong',\n  44: 'voice_prolong',\n  45: 'voice_prolong',\n  46: 'voice',\n  63: 'prolong',\n  64: 'prolong',\n  65: 'palat',\n  66: 'same_cons'},\n 67: {1: 'near_stressed', 67: 'same_stressed'},\n 68: {68: 'same_v'},\n 69: {69: 'same_cons', 70: 'prolong'},\n 70: {69: 'prolong', 70: 'same_cons'},\n 71: {71: 'same_v'},\n 72: {12: 'near_stressed', 72: 'same_stressed'},\n 73: {18: 'voice',\n  19: 'voice',\n  20: 'voice',\n  21: 'voice_prolong',\n  73: 'same_cons',\n  74: 'palat',\n  75: 'prolong'},\n 74: {18: 'prolong',\n  19: 'voice',\n  20: 'voice_prolong',\n  21: 'voice_prolong',\n  73: 'palat',\n  74: 'same_cons',\n  75: 'same_cons'},\n 75: {18: 'voice_prolong',\n  19: 'voice_prolong',\n  20: 'voice_prolong',\n  21: 'voice',\n  73: 'prolong',\n  74: 'prolong',\n  75: 'same_cons'},\n 76: {15: 'near_stressed', 76: 'same_stressed'},\n 77: {77: 'same_v'},\n 78: {34: 'near_stressed', 78: 'same_stressed'},\n 79: {79: 'same_cons', 80: 'prolong', 84: 'voice', 85: 'voice_prolong'},\n 80: {79: 'prolong', 80: 'same_cons', 84: 'voice_prolong', 85: 'voice'},\n 81: {81: 'same_cons'},\n 82: {56: 'near_stressed', 82: 'same_stressed'},\n 83: {83: 'same_v'},\n 84: {79: 'voice', 80: 'voice_prolong', 84: 'same_cons', 85: 'prolong'},\n 85: {79: 'voice_prolong', 80: 'voice', 84: 'prolong', 85: 'same_cons'}}"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_int_dict_int_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "85"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_int_dict_int_pattern)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "85"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_int_dict_int_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "85"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IpaDicts().all_ipa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dill.dump"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "with open(\"similarities_score.pkl\", \"wb\") as f:\n",
    "    dill.dump(dict_int_dict_int_score, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "with open(\"similarities_pat.pkl\", \"wb\") as f:\n",
    "    dill.dump(dict_int_dict_int_pattern, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# dill load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "with open(\"similarities_score.pkl\", \"rb\") as f:\n",
    "    similarities_score = dill.load(f)\n",
    "print(len(similarities_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "with open(\"similarities_pat.pkl\", \"rb\") as f:\n",
    "    similarities_pat = dill.load(f)\n",
    "print(len(similarities_pat))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mysql"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "my_sql = MySql()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "uni_char = 'ɐ'\n",
    "query_0 = f\"select accent, sounds, intipa from wiki_pickled where locate('{uni_char}', sounds) > 0 limit 10\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "sounds_68 = my_sql.cur_execute(query_0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "[(\"баско'й\", 'bɐˈskoj', '[18, 34, 16]'),\n (\"боча'г\", 'bɐˈt͡ɕak', '[54, 1, 18]'),\n (\"браты'ня\", 'brɐˈtɨnʲə', '[47, 76, 31, 71]'),\n (\"баско'й\", 'bɐˈskoj', '[18, 34, 16]'),\n (\"боча'г\", 'bɐˈt͡ɕak', '[54, 1, 18]'),\n (\"браты'ня\", 'brɐˈtɨnʲə', '[47, 76, 31, 71]'),\n (\"произноше'ние\", 'prəɪznɐˈʂɛnʲɪje', '[79, 72, 31, 77, 16, 12]'),\n (\"росси'я\", 'rɐˈsʲijə', '[44, 15, 16, 71]'),\n (\"она'\", 'ɐˈna', '[30, 1]'),\n (\"погро'м\", 'pɐˈɡrom', '[39, 34, 26]')]"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sounds_68"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "central near-open unrounded vowel"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IpaDicts().number2sign[68]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"а'ктуализациям\", 'ɐktʊəlʲɪzət͡sɨjəm', '[68, 18, 47, 83, 71, 22, 77, 63, 71, 51, 76, 16, 71, 26]'), (\"а'ктуализациями\", 'ɐktʊəlʲɪzət͡sɨjəmʲɪ', '[68, 18, 47, 83, 71, 22, 77, 63, 71, 51, 76, 16, 71, 27, 77]'), (\"а'ктуализациях\", 'ɐktʊəlʲɪzət͡sɨjəx', '[68, 18, 47, 83, 71, 22, 77, 63, 71, 51, 76, 16, 71, 61]'), (\"о'босрать\", 'ɐbəsrətʲ', '[68, 2, 71, 43, 39, 71, 48]'), (\"о'бсирать\", 'ɐpsʲɪrətʲ', '[68, 35, 44, 77, 39, 71, 48]')]\n"
     ]
    }
   ],
   "source": [
    "number = 68\n",
    "query_0 = f\"select accent, sounds, intipa from wiki_pickled where locate('{number}', intipa) > 0 limit 10\"\n",
    "sounds_68 = my_sql.cur_execute(query_0)\n",
    "print(sounds_68)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## two words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"ло'гово\", 'ˈɫoɡəvə', '[24, 34, 73, 71, 57, 71]'), (\"кро'шево\", 'ˈkroʂɨvə', '[39, 34, 79, 76, 57, 71]')]\n"
     ]
    }
   ],
   "source": [
    "my_sql = MySql()\n",
    "word_0 = \"ло'гово\"\n",
    "word_1 = \"кро'шево\"\n",
    "query_w_0 = f'''select accent, sounds, intipa from wiki_pickled where accent = \"{word_0}\" or accent = \"{word_1}\"'''\n",
    "intipa = my_sql.cur_execute(query_w_0)\n",
    "print(intipa)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 34, 73, 71, 57, 71]\n",
      "[39, 34, 79, 76, 57, 71]\n"
     ]
    }
   ],
   "source": [
    "intipa_word = json.loads(intipa[0][2])\n",
    "print(intipa_word)\n",
    "intipa_rhyme = json.loads(intipa[1][2])\n",
    "print(intipa_rhyme)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# check similarities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 34, 73, 71, 57, 71]\n",
      "[39, 34, 79, 76, 57, 71]\n",
      "[(\"ло'гово\", 'ˈɫoɡəvə', '[24, 34, 73, 71, 57, 71]'), (\"кро'шево\", 'ˈkroʂɨvə', '[39, 34, 79, 76, 57, 71]')]\n"
     ]
    }
   ],
   "source": [
    "print(intipa_word)\n",
    "print(intipa_rhyme)\n",
    "print(intipa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "{22: 'palat', 23: 'palat', 24: 'same_cons', 25: 'prolong'}\n",
      "34\n",
      "{78: 'near_stressed', 34: 'same_stressed'}\n",
      "73\n",
      "{18: 'voice', 19: 'voice', 20: 'voice', 21: 'voice_prolong', 73: 'same_cons', 74: 'palat', 75: 'prolong'}\n",
      "71\n",
      "{71: 'same_v'}\n",
      "57\n",
      "{13: 'voice', 14: 'voice', 57: 'same_cons', 58: 'palat', 59: 'palat', 60: 'prolong'}\n",
      "71\n",
      "{71: 'same_v'}\n"
     ]
    }
   ],
   "source": [
    "for _int in intipa_word:\n",
    "    similarity = similarities_pat[_int]\n",
    "    print(_int)\n",
    "    print(similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "def get_rhyme_pattern(intipa_word, intipa_rhyme) -> tuple[str]:\n",
    "    word_pattern: list = []\n",
    "    for _int_word, _int_rhyme in zip(intipa_word, intipa_rhyme):\n",
    "        similarity: dict[int, str] = similarities_pat[_int_word]\n",
    "        # print(\"similarity\", similarity)\n",
    "        # print(\"_int_rhyme\", _int_rhyme)\n",
    "        try:\n",
    "            pat: str = similarity[_int_rhyme]\n",
    "            # print(\"pat\", pat)\n",
    "            word_pattern.append(pat)\n",
    "        except KeyError:\n",
    "            if _int_rhyme in IpaDicts().numbers_vowels:\n",
    "                word_pattern.append(\"any_v\")\n",
    "            else:\n",
    "                word_pattern.append(\"any_cons\")\n",
    "            # print(\"exception _int_rhyme\", _int_rhyme)\n",
    "    word_pattern = tuple(word_pattern)\n",
    "    return word_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "('any_cons', 'same_stressed', 'any_cons', 'any_v', 'same_cons', 'same_v')"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pattern = get_rhyme_pattern(intipa_word, intipa_rhyme)\n",
    "word_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"кли'н\", 'klʲin', '[22, 15, 30]'), (\"мы'с\", 'mɨs', '[26, 76, 43]')]\n"
     ]
    }
   ],
   "source": [
    "my_sql = MySql()\n",
    "word_0 = \"мы'с\"\n",
    "word_1 = \"кли'н\"\n",
    "query_w_0 = f'''select accent, sounds, intipa from wiki_pickled where accent = \"{word_0}\" or accent = \"{word_1}\"'''\n",
    "intipa = my_sql.cur_execute(query_w_0)\n",
    "print(intipa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 15, 30]\n",
      "[26, 76, 43]\n"
     ]
    }
   ],
   "source": [
    "intipa_word = json.loads(intipa[0][2])\n",
    "print(intipa_word)\n",
    "intipa_rhyme = json.loads(intipa[1][2])\n",
    "print(intipa_rhyme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "('any_cons', 'near_stressed', 'any_cons')"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pattern = get_rhyme_pattern(intipa_word, intipa_rhyme)\n",
    "word_pattern"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
